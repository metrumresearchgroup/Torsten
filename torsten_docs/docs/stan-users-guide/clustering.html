<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.53">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Clustering Models</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../stan-users-guide/gaussian-processes.html" rel="next">
<link href="../stan-users-guide/sparse-ragged.html" rel="prev">
<link href="../img/logo_tm.png" rel="icon" type="image/png">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 200,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../theming/quarto_styles.css">
</head>

<body class="nav-sidebar floating nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="../index.html" class="navbar-brand navbar-brand-logo">
    <img src="../img/logo_tm.png" alt="Stan logo" class="navbar-logo">
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../index.html"> 
<span class="menu-text">Overview</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link active" href="../stan-users-guide/index.html" aria-current="page"> 
<span class="menu-text">Stan Users Guide</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../reference-manual/index.html"> 
<span class="menu-text">Reference Manual</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../functions-reference/index.html"> 
<span class="menu-text">Functions Reference</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-interfaces" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Interfaces</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-interfaces">    
        <li>
    <a class="dropdown-item" href="../cmdstan-guide/index.html">
 <span class="dropdown-text">CmdStan</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://mc-stan.org/cmdstanpy">
 <span class="dropdown-text">CmdStanPy</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://mc-stan.org/cmdstanr">
 <span class="dropdown-text">CmdStanR</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://mc-stan.org/users/interfaces/pystan.html">
 <span class="dropdown-text">PyStan</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://mc-stan.org/rstan">
 <span class="dropdown-text">RStan</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="http://stanjulia.github.io/Stan.jl/stable/INTRO/">
 <span class="dropdown-text">Stan.jl</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-other-packages" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Other Packages</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-other-packages">    
        <li>
    <a class="dropdown-item" href="https://mc-stan.org/bayesplot/">
 <span class="dropdown-text">bayesplot</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://roualdes.github.io/bridgestan/latest/">
 <span class="dropdown-text">BridgeStan</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://paul-buerkner.github.io/brms/">
 <span class="dropdown-text">brms</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://mc-stan.org/loo/">
 <span class="dropdown-text">loo</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://mc-stan.org/posterior">
 <span class="dropdown-text">posterior</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://mc-stan.org/projpred">
 <span class="dropdown-text">projpred</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://mc-stan.org/rstanarm">
 <span class="dropdown-text">rstanarm</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://mc-stan.org/rstantools">
 <span class="dropdown-text">rstantools</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://mc-stan.org/shinystan">
 <span class="dropdown-text">shinystan</span></a>
  </li>  
    </ul>
  </li>
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools tools-wide">
    <a href="https://github.com/stan-dev" title="" class="quarto-navigation-tool px-1" aria-label=""><i class="bi bi-github"></i></a>
    <a href="https://discourse.mc-stan.org" title="" class="quarto-navigation-tool px-1" aria-label=""><i class="bi bi-chat-text-fill"></i></a>
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Toggle reader mode">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../stan-users-guide/regression.html">Example Models</a></li><li class="breadcrumb-item"><a href="../stan-users-guide/clustering.html">Clustering Models</a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../stan-users-guide/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Stan User’s Guide</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <span class="sidebar-item-text sidebar-link text-start">
 <span class="menu-text">Version 2.35</span></span>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">Example Models</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../stan-users-guide/regression.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Regression Models</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../stan-users-guide/time-series.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Time-Series Models</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../stan-users-guide/missing-data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Missing Data and Partially Known Parameters</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../stan-users-guide/truncation-censoring.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Truncated or Censored Data</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../stan-users-guide/finite-mixtures.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Finite Mixtures</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../stan-users-guide/measurement-error.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Measurement Error and Meta-Analysis</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../stan-users-guide/latent-discrete.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Latent Discrete Parameters</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../stan-users-guide/sparse-ragged.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Sparse and Ragged Data Structures</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../stan-users-guide/clustering.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">Clustering Models</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../stan-users-guide/gaussian-processes.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Gaussian Processes</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../stan-users-guide/hyperspherical-models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Directions, Rotations, and Hyperspheres</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../stan-users-guide/algebraic-equations.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Solving Algebraic Equations</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../stan-users-guide/odes.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Ordinary Differential Equations</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../stan-users-guide/one-dimensional-integrals.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Computing One Dimensional Integrals</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../stan-users-guide/complex-numbers.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Complex Numbers</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../stan-users-guide/dae.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Differential-Algebraic Equations</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../stan-users-guide/survival.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Survival Models</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text">Programming Techniques</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../stan-users-guide/floating-point.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Floating Point Arithmetic</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../stan-users-guide/matrices-arrays.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Matrices, Vectors, Arrays, and Tuples</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../stan-users-guide/multi-indexing.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Multiple Indexing and Range Indexing</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../stan-users-guide/user-functions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">User-Defined Functions</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../stan-users-guide/custom-probability.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Custom Probability Functions</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../stan-users-guide/proportionality-constants.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Proportionality Constants</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../stan-users-guide/problematic-posteriors.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Problematic Posteriors</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../stan-users-guide/reparameterization.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Reparameterization and Change of Variables</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../stan-users-guide/efficiency-tuning.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Efficiency Tuning</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../stan-users-guide/parallelization.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Parallelization</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true">
 <span class="menu-text">Posterior Inference &amp; Model Checking</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../stan-users-guide/posterior-prediction.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Posterior Predictive Sampling</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../stan-users-guide/simulation-based-calibration.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Simulation-Based Calibration</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../stan-users-guide/posterior-predictive-checks.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Posterior and Prior Predictive Checks</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../stan-users-guide/cross-validation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Held-Out Evaluation and Cross-Validation</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../stan-users-guide/poststratification.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Poststratification</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../stan-users-guide/decision-analysis.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Decision Analysis</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../stan-users-guide/bootstrap.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">The Bootstrap and Bagging</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true">
 <span class="menu-text">Appendices</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../stan-users-guide/using-stanc.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Using the Stan Compiler</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../stan-users-guide/style-guide.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Stan Program Style Guide</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../stan-users-guide/for-bugs-users.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Transitioning from BUGS</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#clustering.chapter" id="toc-clustering.chapter" class="nav-link active" data-scroll-target="#clustering.chapter">Clustering Models</a>
  <ul class="collapse">
  <li><a href="#relation-to-finite-mixture-models" id="toc-relation-to-finite-mixture-models" class="nav-link" data-scroll-target="#relation-to-finite-mixture-models">Relation to finite mixture models</a></li>
  <li><a href="#soft-k-means" id="toc-soft-k-means" class="nav-link" data-scroll-target="#soft-k-means">Soft <em>K</em>-means</a>
  <ul class="collapse">
  <li><a href="#geometric-hard-k-means-clustering" id="toc-geometric-hard-k-means-clustering" class="nav-link" data-scroll-target="#geometric-hard-k-means-clustering">Geometric hard <em>K</em>-means clustering</a></li>
  <li><a href="#soft-k-means-clustering" id="toc-soft-k-means-clustering" class="nav-link" data-scroll-target="#soft-k-means-clustering">Soft <em>K</em>-means clustering</a></li>
  <li><a href="#stan-implementation-of-soft-k-means" id="toc-stan-implementation-of-soft-k-means" class="nav-link" data-scroll-target="#stan-implementation-of-soft-k-means">Stan implementation of soft <em>K</em>-means</a></li>
  <li><a href="#generalizing-soft-k-means" id="toc-generalizing-soft-k-means" class="nav-link" data-scroll-target="#generalizing-soft-k-means">Generalizing soft <em>K</em>-means</a></li>
  </ul></li>
  <li><a href="#the-difficulty-of-bayesian-inference-for-clustering" id="toc-the-difficulty-of-bayesian-inference-for-clustering" class="nav-link" data-scroll-target="#the-difficulty-of-bayesian-inference-for-clustering">The difficulty of Bayesian inference for clustering</a>
  <ul class="collapse">
  <li><a href="#non-identifiability" id="toc-non-identifiability" class="nav-link" data-scroll-target="#non-identifiability">Non-identifiability</a></li>
  <li><a href="#multimodality" id="toc-multimodality" class="nav-link" data-scroll-target="#multimodality">Multimodality</a></li>
  </ul></li>
  <li><a href="#naive-bayes-classification-and-clustering" id="toc-naive-bayes-classification-and-clustering" class="nav-link" data-scroll-target="#naive-bayes-classification-and-clustering">Naive Bayes classification and clustering</a>
  <ul class="collapse">
  <li><a href="#coding-ragged-arrays" id="toc-coding-ragged-arrays" class="nav-link" data-scroll-target="#coding-ragged-arrays">Coding ragged arrays</a></li>
  <li><a href="#estimation-with-category-labeled-training-data" id="toc-estimation-with-category-labeled-training-data" class="nav-link" data-scroll-target="#estimation-with-category-labeled-training-data">Estimation with category-labeled training data</a></li>
  <li><a href="#estimation-without-category-labeled-training-data" id="toc-estimation-without-category-labeled-training-data" class="nav-link" data-scroll-target="#estimation-without-category-labeled-training-data">Estimation without category-labeled training data</a></li>
  <li><a href="#full-bayesian-inference-for-naive-bayes" id="toc-full-bayesian-inference-for-naive-bayes" class="nav-link" data-scroll-target="#full-bayesian-inference-for-naive-bayes">Full Bayesian inference for naive Bayes</a></li>
  <li><a href="#prediction-without-model-updates" id="toc-prediction-without-model-updates" class="nav-link" data-scroll-target="#prediction-without-model-updates">Prediction without model updates</a></li>
  </ul></li>
  <li><a href="#latent-dirichlet-allocation" id="toc-latent-dirichlet-allocation" class="nav-link" data-scroll-target="#latent-dirichlet-allocation">Latent Dirichlet allocation</a>
  <ul class="collapse">
  <li><a href="#the-lda-model" id="toc-the-lda-model" class="nav-link" data-scroll-target="#the-lda-model">The LDA Model</a></li>
  <li><a href="#summing-out-the-discrete-parameters" id="toc-summing-out-the-discrete-parameters" class="nav-link" data-scroll-target="#summing-out-the-discrete-parameters">Summing out the discrete parameters</a></li>
  <li><a href="#implementation-of-lda" id="toc-implementation-of-lda" class="nav-link" data-scroll-target="#implementation-of-lda">Implementation of LDA</a></li>
  <li><a href="#correlated-topic-model" id="toc-correlated-topic-model" class="nav-link" data-scroll-target="#correlated-topic-model">Correlated topic model</a></li>
  </ul></li>
  </ul></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.com/stan-dev/docs/edit/master/src/stan-users-guide/clustering.qmd" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li><li><a href="https://github.com/stan-dev/docs/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">




<section id="clustering.chapter" class="level1">
<h1>Clustering Models</h1>
<p>Unsupervised methods for organizing data into groups are collectively referred to as clustering. This chapter describes the implementation in Stan of two widely used statistical clustering models, soft <span class="math inline">\(K\)</span>-means and latent Dirichlet allocation (LDA). In addition, this chapter includes naive Bayesian classification, which can be viewed as a form of clustering which may be supervised. These models are typically expressed using discrete parameters for cluster assignments. Nevertheless, they can be implemented in Stan like any other mixture model by marginalizing out the discrete parameters (see the <a href="../stan-users-guide/finite-mixtures.html">mixture modeling chapter</a>).</p>
<section id="relation-to-finite-mixture-models" class="level2">
<h2 class="anchored" data-anchor-id="relation-to-finite-mixture-models">Relation to finite mixture models</h2>
<p>As mentioned in the <a href="../stan-users-guide/finite-mixtures.html#clustering-mixture.section">clustering section</a>, clustering models and finite mixture models are really just two sides of the same coin. The “soft” <span class="math inline">\(K\)</span>-means model described in the next section is a normal mixture model (with varying assumptions about covariance in higher dimensions leading to variants of <span class="math inline">\(K\)</span>-means). Latent Dirichlet allocation is a mixed-membership multinomial mixture.</p>
</section>
<section id="soft-k-means" class="level2">
<h2 class="anchored" data-anchor-id="soft-k-means">Soft <em>K</em>-means</h2>
<p><span class="math inline">\(K\)</span>-means clustering is a method of clustering data represented as <span class="math inline">\(D\)</span>-dimensional vectors. Specifically, there will be <span class="math inline">\(N\)</span> items to be clustered, each represented as a vector <span class="math inline">\(y_n \in \mathbb{R}^D\)</span>. In the “soft” version of <span class="math inline">\(K\)</span>-means, the assignments to clusters will be probabilistic.</p>
<section id="geometric-hard-k-means-clustering" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="geometric-hard-k-means-clustering">Geometric hard <em>K</em>-means clustering</h3>
<p><span class="math inline">\(K\)</span>-means clustering is typically described geometrically in terms of the following algorithm, which assumes the number of clusters <span class="math inline">\(K\)</span> and data vectors <span class="math inline">\(y\)</span> as input.</p>
<ol type="1">
<li>For each <span class="math inline">\(n\)</span> in <span class="math inline">\(\{1,\dotsc,N\}\)</span>, randomly assign vector <span class="math inline">\(y_n\)</span> to a cluster in <span class="math inline">\(\{1,\dotsc,K\}\)</span>;</li>
<li>Repeat
<ol type="1">
<li>For each cluster <span class="math inline">\(k\)</span> in <span class="math inline">\(\{1,\dotsc,K\}\)</span>, compute the cluster centroid <span class="math inline">\(\mu_k\)</span> by averaging the vectors assigned to that cluster;</li>
<li>For each <span class="math inline">\(n\)</span> in <span class="math inline">\(\{1,\dotsc,N\}\)</span>, reassign <span class="math inline">\(y_n\)</span> to the cluster <span class="math inline">\(k\)</span> for which the (Euclidean) distance from <span class="math inline">\(y_n\)</span> to <span class="math inline">\(\mu_k\)</span> is smallest;</li>
<li>If no vectors changed cluster, return the cluster assignments.</li>
</ol></li>
</ol>
<p>This algorithm is guaranteed to terminate.</p>
</section>
<section id="soft-k-means-clustering" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="soft-k-means-clustering">Soft <em>K</em>-means clustering</h3>
<p>Soft <span class="math inline">\(K\)</span>-means clustering treats the cluster assignments as probability distributions over the clusters. Because of the connection between Euclidean distance and multivariate normal models with a fixed covariance, soft <span class="math inline">\(K\)</span>-means can be expressed (and coded in Stan) as a multivariate normal mixture model.</p>
<p>In the full generative model, each data point <span class="math inline">\(n\)</span> in <span class="math inline">\(\{1,\dotsc,N\}\)</span> is assigned a cluster <span class="math inline">\(z_n \in \{1,\dotsc,K\}\)</span> with symmetric uniform probability, <span class="math display">\[
z_n \sim \textsf{categorical}(1/K),
\]</span> where <span class="math inline">\(1\)</span> is the unit vector of <span class="math inline">\(K\)</span> dimensions, so that <span class="math inline">\(1/K\)</span> is the symmetric <span class="math inline">\(K\)</span>-simplex. Thus the model assumes that each data point is drawn from a hard decision about cluster membership. The softness arises only from the uncertainty about which cluster generated a data point.</p>
<p>The data points themselves are generated from a multivariate normal distribution whose parameters are determined by the cluster assignment <span class="math inline">\(z_n\)</span>, <span class="math display">\[
y_n \sim  \textsf{normal}(\mu_{z[n]},\Sigma_{z[n]})
\]</span></p>
<p>The sample implementation in this section assumes a fixed unit covariance matrix shared by all clusters <span class="math inline">\(k\)</span>, <span class="math display">\[
\Sigma_k = \mathrm{diag\_matrix}({\bf 1}),
\]</span> so that the log multivariate normal can be implemented directly up to a proportion by <span class="math display">\[
\mathrm{normal}\left( y_n \mid \mu_k, \mathrm{diag\_matrix}({\bf 1}) \right)
\propto \exp \left (- \frac{1}{2} \sum_{d=1}^D \left( \mu_{k,d} - y_{n,d}
  \right)^2 \right).
\]</span> The spatial perspective on <span class="math inline">\(K\)</span>-means arises by noting that the inner term is just half the negative Euclidean distance from the cluster mean <span class="math inline">\(\mu_k\)</span> to the data point <span class="math inline">\(y_n\)</span>.</p>
</section>
<section id="stan-implementation-of-soft-k-means" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="stan-implementation-of-soft-k-means">Stan implementation of soft <em>K</em>-means</h3>
<p>Consider the following Stan program for implementing <span class="math inline">\(K\)</span>-means clustering.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode stan code-with-copy"><code class="sourceCode stan"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="kw">data</span> {</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>  <span class="dt">int</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>&gt; N;        <span class="co">// number of data points</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>  <span class="dt">int</span>&lt;<span class="kw">lower</span>=<span class="dv">1</span>&gt; D;        <span class="co">// number of dimensions</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>  <span class="dt">int</span>&lt;<span class="kw">lower</span>=<span class="dv">1</span>&gt; K;        <span class="co">// number of clusters</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>  <span class="dt">array</span>[N] <span class="dt">vector</span>[D] y;  <span class="co">// observations</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="kw">transformed data</span> {</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>  <span class="dt">real</span>&lt;<span class="kw">upper</span>=<span class="dv">0</span>&gt; neg_log_K;</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>  neg_log_K = -log(K);</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="kw">parameters</span> {</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>  <span class="dt">array</span>[K] <span class="dt">vector</span>[D] mu; <span class="co">// cluster means</span></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="kw">transformed parameters</span> {</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>  <span class="dt">array</span>[N, K] <span class="dt">real</span>&lt;<span class="kw">upper</span>=<span class="dv">0</span>&gt; soft_z; <span class="co">// log unnormalized clusters</span></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (n <span class="cf">in</span> <span class="dv">1</span>:N) {</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> (k <span class="cf">in</span> <span class="dv">1</span>:K) {</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>      soft_z[n, k] = neg_log_K</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>                     - <span class="fl">0.5</span> * dot_self(mu[k] - y[n]);</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a><span class="kw">model</span> {</span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>  <span class="co">// prior</span></span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (k <span class="cf">in</span> <span class="dv">1</span>:K) {</span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a>    mu[k] ~ std_normal();</span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a>  <span class="co">// likelihood</span></span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (n <span class="cf">in</span> <span class="dv">1</span>:N) {</span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a>    <span class="kw">target +=</span> log_sum_exp(soft_z[n]);</span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>There is an independent standard normal prior on the centroid parameters; this prior could be swapped with other priors, or even a hierarchical model to fit an overall problem scale and location.</p>
<p>The only parameter is <code>mu</code>, where <code>mu[k]</code> is the centroid for cluster <span class="math inline">\(k\)</span>. The transformed parameters <code>soft_z[n]</code> contain the log of the unnormalized cluster assignment probabilities. The vector <code>soft_z[n]</code> can be converted back to a normalized simplex using the softmax function (see the functions reference manual), either externally or within the model’s generated quantities block.</p>
</section>
<section id="generalizing-soft-k-means" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="generalizing-soft-k-means">Generalizing soft <em>K</em>-means</h3>
<p>The multivariate normal distribution with unit covariance matrix produces a log probability density proportional to Euclidean distance (i.e., <span class="math inline">\(L_2\)</span> distance). Other distributions relate to other geometries. For instance, replacing the normal distribution with the double exponential (Laplace) distribution produces a clustering model based on <span class="math inline">\(L_1\)</span> distance (i.e., Manhattan or taxicab distance).</p>
<p>Within the multivariate normal version of <span class="math inline">\(K\)</span>-means, replacing the unit covariance matrix with a shared covariance matrix amounts to working with distances defined in a space transformed by the inverse covariance matrix.</p>
<p>Although there is no global spatial analog, it is common to see soft <span class="math inline">\(K\)</span>-means specified with a per-cluster covariance matrix. In this situation, a hierarchical prior may be used for the covariance matrices.</p>
</section>
</section>
<section id="the-difficulty-of-bayesian-inference-for-clustering" class="level2">
<h2 class="anchored" data-anchor-id="the-difficulty-of-bayesian-inference-for-clustering">The difficulty of Bayesian inference for clustering</h2>
<p>Two problems make it pretty much impossible to perform full Bayesian inference for clustering models, the lack of parameter identifiability and the extreme multimodality of the posteriors. There is additional discussion related to the non-identifiability due to label switching in the <a href="../stan-users-guide/problematic-posteriors.html#label-switching-problematic.section">label switching section</a>.</p>
<section id="non-identifiability" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="non-identifiability">Non-identifiability</h3>
<p>Cluster assignments are not identified—permuting the cluster mean vectors <code>mu</code> leads to a model with identical likelihoods. For instance, permuting the first two indexes in <code>mu</code> and the first two indexes in each <code>soft_z[n]</code> leads to an identical likelihood (and prior).</p>
<p>The lack of identifiability means that the cluster parameters cannot be compared across multiple Markov chains. In fact, the only parameter in soft <span class="math inline">\(K\)</span>-means is not identified, leading to problems in monitoring convergence. Clusters can even fail to be identified within a single chain, with indices swapping if the chain is long enough or the data are not cleanly separated.</p>
</section>
<section id="multimodality" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="multimodality">Multimodality</h3>
<p>The other problem with clustering models is that their posteriors are highly multimodal. One form of multimodality is the non-identifiability leading to index swapping. But even without the index problems the posteriors are highly multimodal.</p>
<p>Bayesian inference fails in cases of high multimodality because there is no way to visit all of the modes in the posterior in appropriate proportions and thus no way to evaluate integrals involved in posterior predictive inference.</p>
<p>In light of these two problems, the advice often given in fitting clustering models is to try many different initializations and select the sample with the highest overall probability. It is also popular to use optimization-based point estimators such as expectation maximization or variational Bayes, which can be much more efficient than sampling-based approaches.</p>
</section>
</section>
<section id="naive-bayes-classification-and-clustering" class="level2">
<h2 class="anchored" data-anchor-id="naive-bayes-classification-and-clustering">Naive Bayes classification and clustering</h2>
<p>Naive Bayes is a kind of mixture model that can be used for classification or for clustering (or a mix of both), depending on which labels for items are observed.<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a></p>
<p>Multinomial mixture models are referred to as “naive Bayes” because they are often applied to classification problems where the multinomial independence assumptions are clearly false.</p>
<p>Naive Bayes classification and clustering can be applied to any data with multinomial structure. A typical example of this is natural language text classification and clustering, which is used an example in what follows.</p>
<p>The observed data consists of a sequence of <span class="math inline">\(M\)</span> documents made up of bags of words drawn from a vocabulary of <span class="math inline">\(V\)</span> distinct words. A document <span class="math inline">\(m\)</span> has <span class="math inline">\(N_m\)</span> words, which are indexed as <span class="math inline">\(w_{m,1}, \dotsc,
w_{m,N[m]} \in \{1,\dotsc,V\}\)</span>. Despite the ordered indexing of words in a document, this order is not part of the model, which is clearly defective for natural human language data. A number of topics (or categories) <span class="math inline">\(K\)</span> is fixed.</p>
<p>The multinomial mixture model generates a single category <span class="math inline">\(z_m \in
\{1,\dotsc,K\}\)</span> for each document <span class="math inline">\(m \in \{1,\dotsc,M\}\)</span> according to a categorical distribution, <span class="math display">\[
z_m \sim \textsf{categorical}(\theta).
\]</span> The <span class="math inline">\(K\)</span>-simplex parameter <span class="math inline">\(\theta\)</span> represents the prevalence of each category in the data.</p>
<p>Next, the words in each document are generated conditionally independently of each other and the words in other documents based on the category of the document, with word <span class="math inline">\(n\)</span> of document <span class="math inline">\(m\)</span> being generated as <span class="math display">\[
w_{m,n} \sim \textsf{categorical}(\phi_{z[m]}).
\]</span> The parameter <span class="math inline">\(\phi_{z[m]}\)</span> is a <span class="math inline">\(V\)</span>-simplex representing the probability of each word in the vocabulary in documents of category <span class="math inline">\(z_m\)</span>.</p>
<p>The parameters <span class="math inline">\(\theta\)</span> and <span class="math inline">\(\phi\)</span> are typically given symmetric Dirichlet priors. The prevalence <span class="math inline">\(\theta\)</span> is sometimes fixed to produce equal probabilities for each category <span class="math inline">\(k \in \{1,\dotsc,K\}\)</span>.</p>
<section id="coding-ragged-arrays" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="coding-ragged-arrays">Coding ragged arrays</h3>
<p>The specification for naive Bayes in the previous sections have used a ragged array notation for the words <span class="math inline">\(w\)</span>. Because Stan does not support ragged arrays, the models are coded using an alternative strategy that provides an index for each word in a global list of words. The data is organized as follows, with the word arrays laid out in a column and each assigned to its document in a second column.</p>
<p><span class="math display">\[
\begin{array}{lll}
\hline
\mathrm{n} \qquad\qquad\qquad\qquad &amp; \mathrm{w[n]} \qquad &amp; \mathrm{doc[n]} \\
\hline
1         &amp; w_{1,1}    &amp; 1 \\
2         &amp; w_{1,2}    &amp; 1 \\
\vdots &amp; \vdots    &amp; \vdots \\
N_1     &amp; w_{1,N[1]} &amp; 1 \\
N_1 + 1 &amp; w_{2,1}    &amp; 2 \\
N_1 + 2 &amp; w_{2,2}    &amp; 2 \\
\vdots &amp; \vdots    &amp; \vdots \\
N_1 + N_2     &amp; w_{2,N[2]} &amp; 2 \\
N_1 + N_2 + 1 &amp; w_{3,1}    &amp; 3 \\
\vdots       &amp; \vdots    &amp; \vdots \\
N = \sum_{m=1}^M N_m &amp; w_{M,N[M]} &amp; M \\
\hline
\end{array}
\]</span></p>
<p>The relevant variables for the program are <code>N</code>, the total number of words in all the documents, the word array <code>w</code>, and the document identity array <code>doc</code>.</p>
</section>
<section id="estimation-with-category-labeled-training-data" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="estimation-with-category-labeled-training-data">Estimation with category-labeled training data</h3>
<p>A naive Bayes model for estimating the simplex parameters given training data with documents of known categories can be coded in Stan as follows</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode stan code-with-copy"><code class="sourceCode stan"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="kw">data</span> {</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>  <span class="co">// training data</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>  <span class="dt">int</span>&lt;<span class="kw">lower</span>=<span class="dv">1</span>&gt; K;               <span class="co">// num topics</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>  <span class="dt">int</span>&lt;<span class="kw">lower</span>=<span class="dv">1</span>&gt; V;               <span class="co">// num words</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>  <span class="dt">int</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>&gt; M;               <span class="co">// num docs</span></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>  <span class="dt">int</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>&gt; N;               <span class="co">// total word instances</span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>  <span class="dt">array</span>[M] <span class="dt">int</span>&lt;<span class="kw">lower</span>=<span class="dv">1</span>, <span class="kw">upper</span>=K&gt; z;    <span class="co">// topic for doc m</span></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>  <span class="dt">array</span>[N] <span class="dt">int</span>&lt;<span class="kw">lower</span>=<span class="dv">1</span>, <span class="kw">upper</span>=V&gt; w;    <span class="co">// word n</span></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>  <span class="dt">array</span>[N] <span class="dt">int</span>&lt;<span class="kw">lower</span>=<span class="dv">1</span>, <span class="kw">upper</span>=M&gt; doc;  <span class="co">// doc ID for word n</span></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>  <span class="co">// hyperparameters</span></span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>  <span class="dt">vector</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>&gt;[K] alpha;     <span class="co">// topic prior</span></span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>  <span class="dt">vector</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>&gt;[V] beta;      <span class="co">// word prior</span></span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a><span class="kw">parameters</span> {</span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>  <span class="dt">simplex</span>[K] theta;             <span class="co">// topic prevalence</span></span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>  <span class="dt">array</span>[K] <span class="dt">simplex</span>[V] phi;      <span class="co">// word dist for topic k</span></span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a><span class="kw">model</span> {</span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a>  theta ~ dirichlet(alpha);</span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (k <span class="cf">in</span> <span class="dv">1</span>:K) {</span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a>    phi[k] ~ dirichlet(beta);</span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (m <span class="cf">in</span> <span class="dv">1</span>:M) {</span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a>    z[m] ~ categorical(theta);</span>
<span id="cb2-25"><a href="#cb2-25" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb2-26"><a href="#cb2-26" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (n <span class="cf">in</span> <span class="dv">1</span>:N) {</span>
<span id="cb2-27"><a href="#cb2-27" aria-hidden="true" tabindex="-1"></a>    w[n] ~ categorical(phi[z[doc[n]]]);</span>
<span id="cb2-28"><a href="#cb2-28" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb2-29"><a href="#cb2-29" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>The topic identifiers <span class="math inline">\(z_m\)</span> are declared as data and the latent category assignments are included as part of the likelihood function.</p>
</section>
<section id="estimation-without-category-labeled-training-data" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="estimation-without-category-labeled-training-data">Estimation without category-labeled training data</h3>
<p>Naive Bayes models can be used in an unsupervised fashion to cluster multinomial-structured data into a fixed number <span class="math inline">\(K\)</span> of categories. The data declaration includes the same variables as the model in the previous section excluding the topic labels <code>z</code>. Because <code>z</code> is discrete, it needs to be summed out of the model calculation. This is done for naive Bayes as for other mixture models. The parameters are the same up to the priors, but the likelihood is now computed as the marginal document probability</p>
<p><span class="math display">\[\begin{align*}
\log\, &amp;p(w_{m,1},\dotsc,w_{m,N_m} \mid \theta,\phi) \\
&amp;= \log \sum_{k=1}^K
    \left( \textsf{categorical}(k \mid \theta)
           \times \prod_{n=1}^{N_m} \textsf{categorical}(w_{m,n} \mid \phi_k)
    \right) \\
&amp;= \log \sum_{k=1}^K \exp \left(
    \log \textsf{categorical}(k \mid \theta)
     + \sum_{n=1}^{N_m} \log \textsf{categorical}(w_{m,n} \mid \phi_k)
    \right).
\end{align*}\]</span></p>
<p>The last step shows how the <code>log_sum_exp</code> function can be used to stabilize the numerical calculation and return a result on the log scale.</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode stan code-with-copy"><code class="sourceCode stan"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="kw">model</span> {</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>  <span class="dt">array</span>[M, K] <span class="dt">real</span> gamma;</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>  theta ~ dirichlet(alpha);</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (k <span class="cf">in</span> <span class="dv">1</span>:K) {</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>    phi[k] ~ dirichlet(beta);</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (m <span class="cf">in</span> <span class="dv">1</span>:M) {</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> (k <span class="cf">in</span> <span class="dv">1</span>:K) {</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>      gamma[m, k] = categorical_lpmf(k | theta);</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (n <span class="cf">in</span> <span class="dv">1</span>:N) {</span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> (k <span class="cf">in</span> <span class="dv">1</span>:K) {</span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>      gamma[doc[n], k] = gamma[doc[n], k]</span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>                         + categorical_lpmf(w[n] | phi[k]);</span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (m <span class="cf">in</span> <span class="dv">1</span>:M) {</span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a>    <span class="kw">target +=</span> log_sum_exp(gamma[m]);</span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>The local variable <code>gamma[m, k]</code> represents the value <span class="math display">\[
\gamma_{m,k} = \log \textsf{categorical}(k \mid \theta)
+ \sum_{n=1}^{N_m} \log \textsf{categorical}(w_{m,n} \mid \phi_k).
\]</span></p>
<p>Given <span class="math inline">\(\gamma\)</span>, the posterior probability that document <span class="math inline">\(m\)</span> is assigned category <span class="math inline">\(k\)</span> is <span class="math display">\[
\Pr[z_m = k \mid w,\alpha,\beta]
=
\exp \left(
\gamma_{m,k}
- \log \sum_{k=1}^K \exp \left( \gamma_{m,k} \right)
\right).
\]</span></p>
<p>If the variable <code>gamma</code> were declared and defined in the transformed parameter block, its sampled values would be saved by Stan. The normalized posterior probabilities could also be defined as generated quantities.</p>
</section>
<section id="full-bayesian-inference-for-naive-bayes" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="full-bayesian-inference-for-naive-bayes">Full Bayesian inference for naive Bayes</h3>
<p>Full Bayesian posterior predictive inference for the naive Bayes model can be implemented in Stan by combining the models for labeled and unlabeled data. The estimands include both the model parameters and the posterior distribution over categories for the unlabeled data. The model is essentially a missing data model assuming the unknown category labels are missing completely at random; see <span class="citation" data-cites="GelmanEtAl:2013">Gelman et al. (<a href="#ref-GelmanEtAl:2013" role="doc-biblioref">2013</a>)</span> and <span class="citation" data-cites="GelmanHill:2007">Gelman and Hill (<a href="#ref-GelmanHill:2007" role="doc-biblioref">2007</a>)</span> for more information on missing data imputation. The model is also an instance of semisupervised learning because the unlabeled data contributes to the parameter estimations.</p>
<p>To specify a Stan model for performing full Bayesian inference, the model for labeled data is combined with the model for unlabeled data. A second document collection is declared as data, but without the category labels, leading to new variables <code>M2</code> <code>N2</code>, <code>w2</code>, and <code>doc2</code>. The number of categories and number of words, as well as the hyperparameters are shared and only declared once. Similarly, there is only one set of parameters. Then the model contains a single set of statements for the prior, a set of statements for the labeled data, and a set of statements for the unlabeled data.</p>
</section>
<section id="prediction-without-model-updates" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="prediction-without-model-updates">Prediction without model updates</h3>
<p>An alternative to full Bayesian inference involves estimating a model using labeled data, then applying it to unlabeled data without updating the parameter estimates based on the unlabeled data. This behavior can be implemented by moving the definition of <code>gamma</code> for the unlabeled documents to the generated quantities block. Because the variables no longer contribute to the log probability, they no longer jointly contribute to the estimation of the model parameters.</p>
</section>
</section>
<section id="latent-dirichlet-allocation" class="level2">
<h2 class="anchored" data-anchor-id="latent-dirichlet-allocation">Latent Dirichlet allocation</h2>
<p>Latent Dirichlet allocation (LDA) is a mixed-membership multinomial clustering model <span class="citation" data-cites="BleiNgJordan:2003">(<a href="#ref-BleiNgJordan:2003" role="doc-biblioref">Blei, Ng, and Jordan 2003</a>)</span> that generalizes naive Bayes. Using the topic and document terminology common in discussions of LDA, each document is modeled as having a mixture of topics, with each word drawn from a topic based on the mixing proportions.</p>
<section id="the-lda-model" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="the-lda-model">The LDA Model</h3>
<p>The basic model assumes each document is generated independently based on fixed hyperparameters. For document <span class="math inline">\(m\)</span>, the first step is to draw a topic distribution simplex <span class="math inline">\(\theta_m\)</span> over the <span class="math inline">\(K\)</span> topics, <span class="math display">\[
\theta_m \sim \textsf{Dirichlet}(\alpha).
\]</span></p>
<p>The prior hyperparameter <span class="math inline">\(\alpha\)</span> is fixed to a <span class="math inline">\(K\)</span>-vector of positive values. Each word in the document is generated independently conditional on the distribution <span class="math inline">\(\theta_m\)</span>. First, a topic <span class="math inline">\(z_{m,n} \in \{1,\dotsc,K\}\)</span> is drawn for the word based on the document-specific topic-distribution, <span class="math display">\[
z_{m,n} \sim \textsf{categorical}(\theta_m).
\]</span></p>
<p>Finally, the word <span class="math inline">\(w_{m,n}\)</span> is drawn according to the word distribution for topic <span class="math inline">\(z_{m,n}\)</span>, <span class="math display">\[
w_{m,n} \sim \textsf{categorical}(\phi_{z[m,n]}).
\]</span> The distributions <span class="math inline">\(\phi_k\)</span> over words for topic <span class="math inline">\(k\)</span> are also given a Dirichlet prior, <span class="math display">\[
\phi_k \sim \textsf{Dirichlet}(\beta)
\]</span></p>
<p>where <span class="math inline">\(\beta\)</span> is a fixed <span class="math inline">\(V\)</span>-vector of positive values.</p>
</section>
<section id="summing-out-the-discrete-parameters" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="summing-out-the-discrete-parameters">Summing out the discrete parameters</h3>
<p>Although Stan does not (yet) support discrete sampling, it is possible to calculate the marginal distribution over the continuous parameters by summing out the discrete parameters as in other mixture models. The marginal posterior of the topic and word variables is <span class="math display">\[\begin{align*}
p(\theta,\phi \mid w,\alpha,\beta)
&amp;\propto p(\theta \mid \alpha) \, p(\phi \mid \beta) \, p(w \mid \theta,\phi) \\
&amp;= \prod_{m=1}^M p(\theta_m \mid \alpha)
    \times \prod_{k=1}^K p(\phi_k \mid \beta)
    \times \prod_{m=1}^M \prod_{n=1}^{M[n]} p(w_{m,n} \mid \theta_m,\phi).
\end{align*}\]</span></p>
<p>The inner word-probability term is defined by summing out the topic assignments, <span class="math display">\[\begin{align*}
p(w_{m,n} \mid \theta_m,\phi)
&amp;= \sum_{z=1}^K p(z,w_{m,n} \mid \theta_m,\phi) \\
&amp;= \sum_{z=1}^K p(z \mid \theta_m) \, p(w_{m,n} \mid \phi_z).
\end{align*}\]</span></p>
<p>Plugging the distributions in and converting to the log scale provides a formula that can be implemented directly in Stan, <span class="math display">\[\begin{align*}
\log\, &amp;p(\theta,\phi \mid w,\alpha,\beta) \\
&amp;= \sum_{m=1}^M \log \textsf{Dirichlet}(\theta_m \mid \alpha)
    + \sum_{k=1}^K \log \textsf{Dirichlet}(\phi_k \mid \beta) \\
&amp;\qquad + \sum_{m=1}^M \sum_{n=1}^{N[m]} \log \left(
    \sum_{z=1}^K \textsf{categorical}(z \mid \theta_m)
    \times \textsf{categorical}(w_{m,n} \mid \phi_z)
  \right)
\end{align*}\]</span></p>
</section>
<section id="implementation-of-lda" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="implementation-of-lda">Implementation of LDA</h3>
<p>Applying the marginal derived in the last section to the data structure described in this section leads to the following Stan program for LDA.</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode stan code-with-copy"><code class="sourceCode stan"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="kw">data</span> {</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>  <span class="dt">int</span>&lt;<span class="kw">lower</span>=<span class="dv">2</span>&gt; K;               <span class="co">// num topics</span></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>  <span class="dt">int</span>&lt;<span class="kw">lower</span>=<span class="dv">2</span>&gt; V;               <span class="co">// num words</span></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>  <span class="dt">int</span>&lt;<span class="kw">lower</span>=<span class="dv">1</span>&gt; M;               <span class="co">// num docs</span></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>  <span class="dt">int</span>&lt;<span class="kw">lower</span>=<span class="dv">1</span>&gt; N;               <span class="co">// total word instances</span></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>  <span class="dt">array</span>[N] <span class="dt">int</span>&lt;<span class="kw">lower</span>=<span class="dv">1</span>, <span class="kw">upper</span>=V&gt; w;    <span class="co">// word n</span></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>  <span class="dt">array</span>[N] <span class="dt">int</span>&lt;<span class="kw">lower</span>=<span class="dv">1</span>, <span class="kw">upper</span>=M&gt; doc;  <span class="co">// doc ID for word n</span></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>  <span class="dt">vector</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>&gt;[K] alpha;     <span class="co">// topic prior</span></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>  <span class="dt">vector</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>&gt;[V] beta;      <span class="co">// word prior</span></span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a><span class="kw">parameters</span> {</span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>  <span class="dt">array</span>[M] <span class="dt">simplex</span>[K] theta;    <span class="co">// topic dist for doc m</span></span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>  <span class="dt">array</span>[K] <span class="dt">simplex</span>[V] phi;      <span class="co">// word dist for topic k</span></span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a><span class="kw">model</span> {</span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (m <span class="cf">in</span> <span class="dv">1</span>:M) {</span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a>    theta[m] ~ dirichlet(alpha);  <span class="co">// prior</span></span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (k <span class="cf">in</span> <span class="dv">1</span>:K) {</span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a>    phi[k] ~ dirichlet(beta);     <span class="co">// prior</span></span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (n <span class="cf">in</span> <span class="dv">1</span>:N) {</span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a>    <span class="dt">array</span>[K] <span class="dt">real</span> gamma;</span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> (k <span class="cf">in</span> <span class="dv">1</span>:K) {</span>
<span id="cb4-25"><a href="#cb4-25" aria-hidden="true" tabindex="-1"></a>      gamma[k] = log(theta[doc[n], k]) + log(phi[k, w[n]]);</span>
<span id="cb4-26"><a href="#cb4-26" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb4-27"><a href="#cb4-27" aria-hidden="true" tabindex="-1"></a>    <span class="kw">target +=</span> log_sum_exp(gamma);  <span class="co">// likelihood;</span></span>
<span id="cb4-28"><a href="#cb4-28" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb4-29"><a href="#cb4-29" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>As in the other mixture models, the log-sum-of-exponents function is used to stabilize the numerical arithmetic.</p>
</section>
<section id="correlated-topic-model" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="correlated-topic-model">Correlated topic model</h3>
<p>To account for correlations in the distribution of topics for documents, <span class="citation" data-cites="BleiLafferty:2007">Blei and Lafferty (<a href="#ref-BleiLafferty:2007" role="doc-biblioref">2007</a>)</span> introduced a variant of LDA in which the Dirichlet prior on the per-document topic distribution is replaced with a multivariate logistic normal distribution.</p>
<p>The authors treat the prior as a fixed hyperparameter. They use an <span class="math inline">\(L_1\)</span>-regularized estimate of covariance, which is equivalent to the maximum a posteriori estimate given a double-exponential prior. Stan does not (yet) support maximum a posteriori estimation, so the mean and covariance of the multivariate logistic normal must be specified as data.</p>
<section id="fixed-hyperparameter-correlated-topic-model" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="fixed-hyperparameter-correlated-topic-model">Fixed hyperparameter correlated topic model</h4>
<p>The Stan model in the previous section can be modified to implement the correlated topic model by replacing the Dirichlet topic prior <code>alpha</code> in the data declaration with the mean and covariance of the multivariate logistic normal prior.</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode stan code-with-copy"><code class="sourceCode stan"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="kw">data</span> {</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>  <span class="co">// ... data as before without alpha ...</span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>  <span class="dt">vector</span>[K] mu;          <span class="co">// topic mean</span></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>  <span class="dt">cov_matrix</span>[K] Sigma;   <span class="co">// topic covariance</span></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Rather than drawing the simplex parameter <code>theta</code> from a Dirichlet, a parameter <code>eta</code> is drawn from a multivariate normal distribution and then transformed using softmax into a simplex.</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode stan code-with-copy"><code class="sourceCode stan"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="kw">parameters</span> {</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>  <span class="dt">array</span>[K] <span class="dt">simplex</span>[V] phi;     <span class="co">// word dist for topic k</span></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>  <span class="dt">array</span>[M] <span class="dt">vector</span>[K] eta;      <span class="co">// topic dist for doc m</span></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a><span class="kw">transformed parameters</span> {</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>  <span class="dt">array</span>[M] <span class="dt">simplex</span>[K] theta;</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (m <span class="cf">in</span> <span class="dv">1</span>:M) {</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>    theta[m] = softmax(eta[m]);</span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a><span class="kw">model</span> {</span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (m <span class="cf">in</span> <span class="dv">1</span>:M) {</span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a>    eta[m] ~ multi_normal(mu, Sigma);</span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a>  <span class="co">// ... model as before w/o prior for theta ...</span></span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="full-bayes-correlated-topic-model" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="full-bayes-correlated-topic-model">Full Bayes correlated topic model</h4>
<p>By adding a prior for the mean and covariance, Stan supports full Bayesian inference for the correlated topic model. This requires moving the declarations of topic mean <code>mu</code> and covariance <code>Sigma</code> from the data block to the parameters block and providing them with priors in the model. A relatively efficient and interpretable prior for the covariance matrix <code>Sigma</code> may be encoded as follows.</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode stan code-with-copy"><code class="sourceCode stan"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co">// ... data block as before, but without alpha ...</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="kw">parameters</span> {</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>  <span class="dt">vector</span>[K] mu;              <span class="co">// topic mean</span></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>  <span class="dt">corr_matrix</span>[K] Omega;      <span class="co">// correlation matrix</span></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>  <span class="dt">vector</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>&gt;[K] sigma;  <span class="co">// scales</span></span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>  <span class="dt">array</span>[M] <span class="dt">vector</span>[K] eta;    <span class="co">// logit topic dist for doc m</span></span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>  <span class="dt">array</span>[K] <span class="dt">simplex</span>[V] phi;   <span class="co">// word dist for topic k</span></span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a><span class="kw">transformed parameters</span> {</span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>  <span class="co">// ... eta as above ...</span></span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>  <span class="dt">cov_matrix</span>[K] Sigma;       <span class="co">// covariance matrix</span></span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (m <span class="cf">in</span> <span class="dv">1</span>:K) {</span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a>    Sigma[m, m] = sigma[m] * sigma[m] * Omega[m, m];</span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (m <span class="cf">in</span> <span class="dv">1</span>:(K<span class="dv">-1</span>)) {</span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> (n <span class="cf">in</span> (m+<span class="dv">1</span>):K) {</span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a>      Sigma[m, n] = sigma[m] * sigma[n] * Omega[m, n];</span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a>      Sigma[n, m] = Sigma[m, n];</span>
<span id="cb7-19"><a href="#cb7-19" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb7-20"><a href="#cb7-20" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb7-21"><a href="#cb7-21" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb7-22"><a href="#cb7-22" aria-hidden="true" tabindex="-1"></a><span class="kw">model</span> {</span>
<span id="cb7-23"><a href="#cb7-23" aria-hidden="true" tabindex="-1"></a>  mu ~ normal(<span class="dv">0</span>, <span class="dv">5</span>);      <span class="co">// vectorized, diffuse</span></span>
<span id="cb7-24"><a href="#cb7-24" aria-hidden="true" tabindex="-1"></a>  Omega ~ lkj_corr(<span class="fl">2.0</span>);  <span class="co">// regularize to unit correlation</span></span>
<span id="cb7-25"><a href="#cb7-25" aria-hidden="true" tabindex="-1"></a>  sigma ~ cauchy(<span class="dv">0</span>, <span class="dv">5</span>);   <span class="co">// half-Cauchy due to constraint</span></span>
<span id="cb7-26"><a href="#cb7-26" aria-hidden="true" tabindex="-1"></a>  <span class="co">// ... words sampled as above ...</span></span>
<span id="cb7-27"><a href="#cb7-27" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>The <span class="math inline">\(\textsf{LKJCorr}\)</span> distribution with shape <span class="math inline">\(\alpha &gt; 0\)</span> has support on correlation matrices (i.e., symmetric positive definite with unit diagonal). Its density is defined by <span class="math display">\[
\mathsf{LkjCorr}(\Omega\mid\alpha) \propto \mathrm{det}(\Omega)^{\alpha - 1}
\]</span> With a scale of <span class="math inline">\(\alpha = 2\)</span>, the weakly informative prior favors a unit correlation matrix. Thus the compound effect of this prior on the covariance matrix <span class="math inline">\(\Sigma\)</span> for the multivariate logistic normal is a slight concentration around diagonal covariance matrices with scales determined by the prior on <code>sigma</code>.</p>



</section>
</section>
</section>
</section>


<a onclick="window.scrollTo(0, 0); return false;" role="button" id="quarto-back-to-top"><i class="bi bi-arrow-up"></i> Back to top</a><div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-BleiLafferty:2007" class="csl-entry" role="listitem">
Blei, David M., and John D. Lafferty. 2007. <span>“A Correlated Topic Model of <em><span>S</span>cience</em>.”</span> <em>The Annals of Applied Statistics</em> 1 (1): 17–37.
</div>
<div id="ref-BleiNgJordan:2003" class="csl-entry" role="listitem">
Blei, David M., Andrew Y. Ng, and Michael I. Jordan. 2003. <span>“Latent <span>D</span>irichlet Allocation.”</span> <em>Journal of Machine Learning Research</em> 3: 993–1022.
</div>
<div id="ref-GelmanEtAl:2013" class="csl-entry" role="listitem">
Gelman, Andrew, J. B. Carlin, Hal S. Stern, David B. Dunson, Aki Vehtari, and Donald B. Rubin. 2013. <em>Bayesian Data Analysis</em>. Third Edition. London: Chapman &amp; Hall / CRC Press.
</div>
<div id="ref-GelmanHill:2007" class="csl-entry" role="listitem">
Gelman, Andrew, and Jennifer Hill. 2007. <em>Data Analysis Using Regression and Multilevel-Hierarchical Models</em>. Cambridge, United Kingdom: Cambridge University Press.
</div>
</div></section><section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>For clustering, the non-identifiability problems for all mixture models present a problem, whereas there is no such problem for classification. Despite the difficulties with full Bayesian inference for clustering, researchers continue to use it, often in an exploratory data analysis setting rather than for predictive modeling.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
    const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
    const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
    let newTheme = '';
    if(darkModeDefault) {
      newTheme = isAlternate ? baseTheme : alternateTheme;
    } else {
      newTheme = isAlternate ? alternateTheme : baseTheme;
    }
    const changeGiscusTheme = () => {
      // From: https://github.com/giscus/giscus/issues/336
      const sendMessage = (message) => {
        const iframe = document.querySelector('iframe.giscus-frame');
        if (!iframe) return;
        iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
      }
      sendMessage({
        setConfig: {
          theme: newTheme
        }
      });
    }
    const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
    if (isGiscussLoaded) {
      changeGiscusTheme();
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  const darkModeDefault = false;
  let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
    toggleGiscusIfUsed(toAlternate, darkModeDefault);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../stan-users-guide/sparse-ragged.html" class="pagination-link" aria-label="Sparse and Ragged Data Structures">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text">Sparse and Ragged Data Structures</span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../stan-users-guide/gaussian-processes.html" class="pagination-link" aria-label="Gaussian Processes">
        <span class="nav-page-text">Gaussian Processes</span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




<footer class="footer"><div class="nav-footer"><div class="nav-footer-center"><div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/stan-dev/docs/edit/master/src/stan-users-guide/clustering.qmd" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li><li><a href="https://github.com/stan-dev/docs/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div></div></div></footer></body></html>
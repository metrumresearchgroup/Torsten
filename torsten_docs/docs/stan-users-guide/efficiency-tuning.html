<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.53">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Efficiency Tuning</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../stan-users-guide/parallelization.html" rel="next">
<link href="../stan-users-guide/reparameterization.html" rel="prev">
<link href="../img/logo_tm.png" rel="icon" type="image/png">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 200,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../theming/quarto_styles.css">
</head>

<body class="nav-sidebar floating nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="../index.html" class="navbar-brand navbar-brand-logo">
    <img src="../img/logo_tm.png" alt="Stan logo" class="navbar-logo">
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../index.html"> 
<span class="menu-text">Overview</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link active" href="../stan-users-guide/index.html" aria-current="page"> 
<span class="menu-text">Stan Users Guide</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../reference-manual/index.html"> 
<span class="menu-text">Reference Manual</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../functions-reference/index.html"> 
<span class="menu-text">Functions Reference</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-interfaces" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Interfaces</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-interfaces">    
        <li>
    <a class="dropdown-item" href="../cmdstan-guide/index.html">
 <span class="dropdown-text">CmdStan</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://mc-stan.org/cmdstanpy">
 <span class="dropdown-text">CmdStanPy</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://mc-stan.org/cmdstanr">
 <span class="dropdown-text">CmdStanR</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://mc-stan.org/users/interfaces/pystan.html">
 <span class="dropdown-text">PyStan</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://mc-stan.org/rstan">
 <span class="dropdown-text">RStan</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="http://stanjulia.github.io/Stan.jl/stable/INTRO/">
 <span class="dropdown-text">Stan.jl</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-other-packages" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Other Packages</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-other-packages">    
        <li>
    <a class="dropdown-item" href="https://mc-stan.org/bayesplot/">
 <span class="dropdown-text">bayesplot</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://roualdes.github.io/bridgestan/latest/">
 <span class="dropdown-text">BridgeStan</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://paul-buerkner.github.io/brms/">
 <span class="dropdown-text">brms</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://mc-stan.org/loo/">
 <span class="dropdown-text">loo</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://mc-stan.org/posterior">
 <span class="dropdown-text">posterior</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://mc-stan.org/projpred">
 <span class="dropdown-text">projpred</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://mc-stan.org/rstanarm">
 <span class="dropdown-text">rstanarm</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://mc-stan.org/rstantools">
 <span class="dropdown-text">rstantools</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://mc-stan.org/shinystan">
 <span class="dropdown-text">shinystan</span></a>
  </li>  
    </ul>
  </li>
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools tools-wide">
    <a href="https://github.com/stan-dev" title="" class="quarto-navigation-tool px-1" aria-label=""><i class="bi bi-github"></i></a>
    <a href="https://discourse.mc-stan.org" title="" class="quarto-navigation-tool px-1" aria-label=""><i class="bi bi-chat-text-fill"></i></a>
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Toggle reader mode">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../stan-users-guide/floating-point.html">Programming Techniques</a></li><li class="breadcrumb-item"><a href="../stan-users-guide/efficiency-tuning.html">Efficiency Tuning</a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../stan-users-guide/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Stan User’s Guide</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <span class="sidebar-item-text sidebar-link text-start">
 <span class="menu-text">Version 2.35</span></span>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">Example Models</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../stan-users-guide/regression.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Regression Models</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../stan-users-guide/time-series.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Time-Series Models</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../stan-users-guide/missing-data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Missing Data and Partially Known Parameters</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../stan-users-guide/truncation-censoring.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Truncated or Censored Data</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../stan-users-guide/finite-mixtures.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Finite Mixtures</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../stan-users-guide/measurement-error.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Measurement Error and Meta-Analysis</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../stan-users-guide/latent-discrete.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Latent Discrete Parameters</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../stan-users-guide/sparse-ragged.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Sparse and Ragged Data Structures</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../stan-users-guide/clustering.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Clustering Models</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../stan-users-guide/gaussian-processes.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Gaussian Processes</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../stan-users-guide/hyperspherical-models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Directions, Rotations, and Hyperspheres</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../stan-users-guide/algebraic-equations.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Solving Algebraic Equations</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../stan-users-guide/odes.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Ordinary Differential Equations</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../stan-users-guide/one-dimensional-integrals.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Computing One Dimensional Integrals</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../stan-users-guide/complex-numbers.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Complex Numbers</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../stan-users-guide/dae.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Differential-Algebraic Equations</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../stan-users-guide/survival.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Survival Models</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text">Programming Techniques</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../stan-users-guide/floating-point.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Floating Point Arithmetic</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../stan-users-guide/matrices-arrays.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Matrices, Vectors, Arrays, and Tuples</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../stan-users-guide/multi-indexing.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Multiple Indexing and Range Indexing</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../stan-users-guide/user-functions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">User-Defined Functions</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../stan-users-guide/custom-probability.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Custom Probability Functions</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../stan-users-guide/proportionality-constants.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Proportionality Constants</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../stan-users-guide/problematic-posteriors.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Problematic Posteriors</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../stan-users-guide/reparameterization.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Reparameterization and Change of Variables</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../stan-users-guide/efficiency-tuning.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">Efficiency Tuning</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../stan-users-guide/parallelization.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Parallelization</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true">
 <span class="menu-text">Posterior Inference &amp; Model Checking</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../stan-users-guide/posterior-prediction.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Posterior Predictive Sampling</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../stan-users-guide/simulation-based-calibration.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Simulation-Based Calibration</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../stan-users-guide/posterior-predictive-checks.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Posterior and Prior Predictive Checks</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../stan-users-guide/cross-validation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Held-Out Evaluation and Cross-Validation</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../stan-users-guide/poststratification.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Poststratification</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../stan-users-guide/decision-analysis.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Decision Analysis</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../stan-users-guide/bootstrap.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">The Bootstrap and Bagging</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true">
 <span class="menu-text">Appendices</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../stan-users-guide/using-stanc.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Using the Stan Compiler</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../stan-users-guide/style-guide.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Stan Program Style Guide</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../stan-users-guide/for-bugs-users.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Transitioning from BUGS</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#efficiency-tuning.chapter" id="toc-efficiency-tuning.chapter" class="nav-link active" data-scroll-target="#efficiency-tuning.chapter">Efficiency Tuning</a>
  <ul class="collapse">
  <li><a href="#what-is-efficiency" id="toc-what-is-efficiency" class="nav-link" data-scroll-target="#what-is-efficiency">What is efficiency?</a></li>
  <li><a href="#efficiency-for-probabilistic-models-and-algorithms" id="toc-efficiency-for-probabilistic-models-and-algorithms" class="nav-link" data-scroll-target="#efficiency-for-probabilistic-models-and-algorithms">Efficiency for probabilistic models and algorithms</a></li>
  <li><a href="#statistical-vs.-computational-efficiency" id="toc-statistical-vs.-computational-efficiency" class="nav-link" data-scroll-target="#statistical-vs.-computational-efficiency">Statistical vs.&nbsp; computational efficiency</a></li>
  <li><a href="#model-conditioning-and-curvature" id="toc-model-conditioning-and-curvature" class="nav-link" data-scroll-target="#model-conditioning-and-curvature">Model conditioning and curvature</a>
  <ul class="collapse">
  <li><a href="#condition-number-and-adaptation" id="toc-condition-number-and-adaptation" class="nav-link" data-scroll-target="#condition-number-and-adaptation">Condition number and adaptation</a></li>
  <li><a href="#unit-scales-without-correlation" id="toc-unit-scales-without-correlation" class="nav-link" data-scroll-target="#unit-scales-without-correlation">Unit scales without correlation</a></li>
  <li><a href="#varying-curvature" id="toc-varying-curvature" class="nav-link" data-scroll-target="#varying-curvature">Varying curvature</a></li>
  <li><a href="#reparameterizing-with-a-change-of-variables" id="toc-reparameterizing-with-a-change-of-variables" class="nav-link" data-scroll-target="#reparameterizing-with-a-change-of-variables">Reparameterizing with a change of variables</a></li>
  </ul></li>
  <li><a href="#well-specified-models" id="toc-well-specified-models" class="nav-link" data-scroll-target="#well-specified-models">Well-specified models</a></li>
  <li><a href="#avoiding-validation" id="toc-avoiding-validation" class="nav-link" data-scroll-target="#avoiding-validation">Avoiding validation</a></li>
  <li><a href="#reparameterization.section" id="toc-reparameterization.section" class="nav-link" data-scroll-target="#reparameterization.section">Reparameterization</a>
  <ul class="collapse">
  <li><a href="#funnel.figure" id="toc-funnel.figure" class="nav-link" data-scroll-target="#funnel.figure">Example: Neal’s funnel</a></li>
  <li><a href="#reparameterizing-the-cauchy" id="toc-reparameterizing-the-cauchy" class="nav-link" data-scroll-target="#reparameterizing-the-cauchy">Reparameterizing the Cauchy</a></li>
  <li><a href="#reparameterizing-a-student-t-distribution" id="toc-reparameterizing-a-student-t-distribution" class="nav-link" data-scroll-target="#reparameterizing-a-student-t-distribution">Reparameterizing a Student-t distribution</a></li>
  <li><a href="#hierarchical-models-and-the-non-centered-parameterization" id="toc-hierarchical-models-and-the-non-centered-parameterization" class="nav-link" data-scroll-target="#hierarchical-models-and-the-non-centered-parameterization">Hierarchical models and the non-centered parameterization</a></li>
  <li><a href="#non-centered-parameterization" id="toc-non-centered-parameterization" class="nav-link" data-scroll-target="#non-centered-parameterization">Non-centered parameterization</a></li>
  <li><a href="#multivariate-reparameterizations" id="toc-multivariate-reparameterizations" class="nav-link" data-scroll-target="#multivariate-reparameterizations">Multivariate reparameterizations</a></li>
  </ul></li>
  <li><a href="#vectorization" id="toc-vectorization" class="nav-link" data-scroll-target="#vectorization">Vectorization</a>
  <ul class="collapse">
  <li><a href="#gradient-bottleneck" id="toc-gradient-bottleneck" class="nav-link" data-scroll-target="#gradient-bottleneck">Gradient bottleneck</a></li>
  <li><a href="#vectorizing-summations" id="toc-vectorizing-summations" class="nav-link" data-scroll-target="#vectorizing-summations">Vectorizing summations</a></li>
  <li><a href="#vectorization-through-matrix-operations" id="toc-vectorization-through-matrix-operations" class="nav-link" data-scroll-target="#vectorization-through-matrix-operations">Vectorization through matrix operations</a></li>
  <li><a href="#vectorized-probability-functions" id="toc-vectorized-probability-functions" class="nav-link" data-scroll-target="#vectorized-probability-functions">Vectorized probability functions</a></li>
  <li><a href="#reshaping-data-for-vectorization" id="toc-reshaping-data-for-vectorization" class="nav-link" data-scroll-target="#reshaping-data-for-vectorization">Reshaping data for vectorization</a></li>
  </ul></li>
  <li><a href="#exploiting-sufficient-statistics" id="toc-exploiting-sufficient-statistics" class="nav-link" data-scroll-target="#exploiting-sufficient-statistics">Exploiting sufficient statistics</a>
  <ul class="collapse">
  <li><a href="#bernoulli-sufficient-statistics" id="toc-bernoulli-sufficient-statistics" class="nav-link" data-scroll-target="#bernoulli-sufficient-statistics">Bernoulli sufficient statistics</a></li>
  <li><a href="#normal-sufficient-statistics" id="toc-normal-sufficient-statistics" class="nav-link" data-scroll-target="#normal-sufficient-statistics">Normal sufficient statistics</a></li>
  <li><a href="#poisson-sufficient-statistics" id="toc-poisson-sufficient-statistics" class="nav-link" data-scroll-target="#poisson-sufficient-statistics">Poisson sufficient statistics</a></li>
  </ul></li>
  <li><a href="#aggregating-common-subexpressions" id="toc-aggregating-common-subexpressions" class="nav-link" data-scroll-target="#aggregating-common-subexpressions">Aggregating common subexpressions</a></li>
  <li><a href="#exploiting-conjugacy" id="toc-exploiting-conjugacy" class="nav-link" data-scroll-target="#exploiting-conjugacy">Exploiting conjugacy</a></li>
  <li><a href="#standardizing-predictors" id="toc-standardizing-predictors" class="nav-link" data-scroll-target="#standardizing-predictors">Standardizing predictors</a>
  <ul class="collapse">
  <li><a href="#standard-normal-distribution" id="toc-standard-normal-distribution" class="nav-link" data-scroll-target="#standard-normal-distribution">Standard normal distribution</a></li>
  </ul></li>
  <li><a href="#using-map-reduce" id="toc-using-map-reduce" class="nav-link" data-scroll-target="#using-map-reduce">Using map-reduce</a></li>
  </ul></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.com/stan-dev/docs/edit/master/src/stan-users-guide/efficiency-tuning.qmd" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li><li><a href="https://github.com/stan-dev/docs/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">




<section id="efficiency-tuning.chapter" class="level1">
<h1>Efficiency Tuning</h1>
<p>This chapter provides a grab bag of techniques for optimizing Stan code, including vectorization, sufficient statistics, and conjugacy. At a coarse level, efficiency involves both the amount of time required for a computation and the amount of memory required. For practical applied statistical modeling, we are mainly concerned with reducing wall time (how long a program takes as measured by a clock on the wall) and keeping memory requirements within available bounds.</p>
<section id="what-is-efficiency" class="level2">
<h2 class="anchored" data-anchor-id="what-is-efficiency">What is efficiency?</h2>
<p>The standard algorithm analyses in computer science measure efficiency asymptotically as a function of problem size (such as data, number of parameters, etc.) and typically do not consider constant additive factors like startup times or multiplicative factors like speed of operations. In practice, the constant factors are important; if run time can be cut in half or more, that’s a huge gain. This chapter focuses on both the constant factors involved in efficiency (such as using built-in matrix operations as opposed to naive loops) and on asymptotic efficiency factors (such as using linear algorithms instead of quadratic algorithms in loops).</p>
</section>
<section id="efficiency-for-probabilistic-models-and-algorithms" class="level2">
<h2 class="anchored" data-anchor-id="efficiency-for-probabilistic-models-and-algorithms">Efficiency for probabilistic models and algorithms</h2>
<p>Stan programs express models which are intrinsically statistical in nature. The algorithms applied to these models may or may not themselves be probabilistic. For example, given an initial value for parameters (which may itself be given deterministically or generated randomly), Stan’s optimization algorithm (L-BFGS) for penalized maximum likelihood estimation is purely deterministic. Stan’s sampling algorithms are based on Markov chain Monte Carlo algorithms, which are probabilistic by nature at every step. Stan’s variational inference algorithm (ADVI) is probabilistic despite being an optimization algorithm; the randomization lies in a nested Monte Carlo calculation for an expected gradient.</p>
<p>With probabilistic algorithms, there will be variation in run times (and maybe memory usage) based on the randomization involved. For example, by starting too far out in the tail, iterative algorithms underneath the hood, such as the solvers for ordinary differential equations, may take different numbers of steps. Ideally this variation will be limited; when there is a lot of variation it can be a sign that there is a problem with the model’s parameterization in a Stan program or with initialization.</p>
<p>A well-behaved Stan program will have low variance between runs with different random initializations and differently seeded random number generators. But sometimes an algorithm can get stuck in one part of the posterior, typically due to high curvature. Such sticking almost always indicates the need to reparameterize the model. Just throwing away Markov chains with apparently poor behavior (slow, or stuck) can lead to bias in posterior estimates. This problem with getting stuck can often be overcome by lowering the initial step size to avoid getting stuck during adaptation and increasing the target acceptance rate in order to target a lower step size. This is because smaller step sizes allow Stan’s gradient-based algorithms to better follow the curvature in the density or penalized maximum likelihood being fit.</p>
</section>
<section id="statistical-vs.-computational-efficiency" class="level2">
<h2 class="anchored" data-anchor-id="statistical-vs.-computational-efficiency">Statistical vs.&nbsp; computational efficiency</h2>
<p>There is a difference between pure computational efficiency and statistical efficiency for Stan programs fit with sampling-based algorithms. Computational efficiency measures the amount of time or memory required for a given step in a calculation, such as an evaluation of a log posterior or penalized likelihood.</p>
<p>Statistical efficiency typically involves requiring fewer steps in algorithms by making the statistical formulation of a model better behaved. The typical way to do this is by applying a change of variables (i.e., reparameterization) so that sampling algorithms mix better or optimization algorithms require less adaptation.</p>
</section>
<section id="model-conditioning-and-curvature" class="level2">
<h2 class="anchored" data-anchor-id="model-conditioning-and-curvature">Model conditioning and curvature</h2>
<p>Because Stan’s algorithms rely on step-based gradient-based approximations of the density (or penalized maximum likelihood) being fitted, posterior curvature not captured by this first-order approximation plays a central role in determining the statistical efficiency of Stan’s algorithms.</p>
<p>A second-order approximation to curvature is provided by the Hessian, the matrix of second derivatives of the log density <span class="math inline">\(\log
p(\theta)\)</span> with respect to the parameter vector <span class="math inline">\(\theta\)</span>, defined as <span class="math display">\[
H(\theta) = \nabla \, \nabla \, \log p(\theta \mid y),
\]</span> so that <span class="math display">\[
H_{i, j}(\theta) = \frac{\partial^2 \log p(\theta \mid y)}
                {\partial \theta_i \ \partial \theta_j}.
\]</span> For pure penalized maximum likelihood problems, the posterior log density <span class="math inline">\(\log p(\theta \mid y)\)</span> is replaced by the penalized likelihood function <span class="math inline">\(\mathcal{L}(\theta) = \log p(y \mid \theta) - \lambda(\theta)\)</span>.</p>
<section id="condition-number-and-adaptation" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="condition-number-and-adaptation">Condition number and adaptation</h3>
<p>A good gauge of how difficult a problem the curvature presents is given by the condition number of the Hessian matrix <span class="math inline">\(H\)</span>, which is the ratio of the largest to the smallest eigenvalue of <span class="math inline">\(H\)</span> (assuming the Hessian is positive definite). This essentially measures the difference between the flattest direction of movement and the most curved. Typically, the step size of a gradient-based algorithm is bounded by the most sharply curved direction. With better conditioned log densities or penalized likelihood functions, it is easier for Stan’s adaptation, especially the diagonal adaptations that are used as defaults.</p>
</section>
<section id="unit-scales-without-correlation" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="unit-scales-without-correlation">Unit scales without correlation</h3>
<p>Ideally, all parameters should be programmed so that they have unit scale and so that posterior correlation is reduced; together, these properties mean that there is no rotation or scaling required for optimal performance of Stan’s algorithms. For Hamiltonian Monte Carlo, this implies a unit mass matrix, which requires no adaptation as it is where the algorithm initializes.</p>
</section>
<section id="varying-curvature" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="varying-curvature">Varying curvature</h3>
<p>In all but very simple models (such as multivariate normals), the Hessian will vary as <span class="math inline">\(\theta\)</span> varies (an extreme example is Neal’s funnel, as naturally arises in hierarchical models with little or no data). The more the curvature varies, the harder it is for all of the algorithms with fixed adaptation parameters to find adaptations that cover the entire density well. Many of the variable transforms proposed are aimed at improving the conditioning of the Hessian and/or making it more consistent across the relevant portions of the density (or penalized maximum likelihood function) being fit.</p>
<p>For all of Stan’s algorithms, the curvature along the path from the initial values of the parameters to the solution is relevant. For penalized maximum likelihood and variational inference, the solution of the iterative algorithm will be a single point, so this is all that matters. For sampling, the relevant “solution” is the typical set, which is the posterior volume where almost all draws from the posterior lies; thus, the typical set contains almost all of the posterior probability mass.</p>
<p>With sampling, the curvature may vary dramatically between the points on the path from the initialization point to the typical set and within the typical set. This is why adaptation needs to run long enough to visit enough points in the typical set to get a good first-order estimate of the curvature within the typical set. If adaptation is not run long enough, sampling within the typical set after adaptation will not be efficient. We generally recommend at least one hundred iterations after the typical set is reached (and the first effective draw is ready to be realized). Whether adaptation has run long enough can be measured by comparing the adaptation parameters derived from a set of diffuse initial parameter values.</p>
</section>
<section id="reparameterizing-with-a-change-of-variables" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="reparameterizing-with-a-change-of-variables">Reparameterizing with a change of variables</h3>
<p>Improving statistical efficiency is achieved by reparameterizing the model so that the same result may be calculated using a density or penalized maximum likelihood that is better conditioned. Again, see the example of reparameterizing Neal’s funnel for an example, and also the examples in the <a href="../stan-users-guide/reparameterization.html">change of variables chapter</a>.</p>
<p>One has to be careful in using change-of-variables reparameterizations when using maximum likelihood estimation, because they can change the result if the Jacobian term is inadvertently included in the revised likelihood model.</p>
</section>
</section>
<section id="well-specified-models" class="level2">
<h2 class="anchored" data-anchor-id="well-specified-models">Well-specified models</h2>
<p>Model misspecification, which roughly speaking means using a model that doesn’t match the data, can be a major source of slow code. This can be seen in cases where simulated data according to the model runs robustly and efficiently, whereas the real data for which it was intended runs slowly or may even have convergence and mixing issues. While some of the techniques recommended in the remaining sections of this chapter may mitigate the problem, the best remedy is a better model specification.</p>
<p>Counterintuitively, more complicated models often run faster than simpler models. One common pattern is with a group of parameters with a wide fixed prior such as <code>normal(0, 1000)</code>). This can fit slowly due to the mismatch between prior and posterior (the prior has support for values in the hundreds or even thousands, whereas the posterior may be concentrated near zero). In such cases, replacing the fixed prior with a hierarchical prior such as <code>normal(mu,   sigma)</code>, where <code>mu</code> and <code>sigma</code> are new parameters with their own hyperpriors, can be beneficial.</p>
</section>
<section id="avoiding-validation" class="level2">
<h2 class="anchored" data-anchor-id="avoiding-validation">Avoiding validation</h2>
<p>Stan validates all of its data structure constraints. For example, consider a transformed parameter defined to be a covariance matrix and then used as a covariance parameter in the model block.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode stan code-with-copy"><code class="sourceCode stan"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="kw">transformed parameters</span> {</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>  <span class="dt">cov_matrix</span>[K] Sigma;</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>  <span class="co">// ...</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>}                               <span class="co">// first validation</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="kw">model</span> {</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>  y ~ multi_normal(mu, Sigma);  <span class="co">// second validation</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>  <span class="co">// ...</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Because <code>Sigma</code> is declared to be a covariance matrix, it will be factored at the end of the transformed parameter block to ensure that it is positive definite. The multivariate normal log density function also validates that <code>Sigma</code> is positive definite. This test is expensive, having cubic run time (i.e., <span class="math inline">\(\mathcal{O}(N^3)\)</span> for <span class="math inline">\(N \times N\)</span> matrices), so it should not be done twice.</p>
<p>The test may be avoided by simply declaring <code>Sigma</code> to be a simple unconstrained matrix.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode stan code-with-copy"><code class="sourceCode stan"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="kw">transformed parameters</span> {</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>  <span class="dt">matrix</span>[K, K] Sigma;</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>  <span class="co">// ...</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="kw">model</span> {</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>  y ~ multi_normal(mu, Sigma);  <span class="co">// only validation</span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Now the only validation is carried out by the multivariate normal.</p>
</section>
<section id="reparameterization.section" class="level2">
<h2 class="anchored" data-anchor-id="reparameterization.section">Reparameterization</h2>
<p>Stan’s sampler can be slow in sampling from distributions with difficult posterior geometries. One way to speed up such models is through reparameterization. In some cases, reparameterization can dramatically increase effective sample size for the same number of iterations or even make programs that would not converge well behaved.</p>
<section id="funnel.figure" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="funnel.figure">Example: Neal’s funnel</h3>
<p>In this section, we discuss a general transform from a centered to a non-centered parameterization <span class="citation" data-cites="papa-et-al:2007">(<a href="#ref-papa-et-al:2007" role="doc-biblioref">Papaspiliopoulos, Roberts, and Sköld 2007</a>)</span>.<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a></p>
<p>This reparameterization is helpful when there is not much data, because it separates the hierarchical parameters and lower-level parameters in the prior.</p>
<p><span class="citation" data-cites="Neal:2003">Neal (<a href="#ref-Neal:2003" role="doc-biblioref">2003</a>)</span> defines a distribution that exemplifies the difficulties of sampling from some hierarchical models. Neal’s example is fairly extreme, but can be trivially reparameterized in such a way as to make sampling straightforward. Neal’s example has support for <span class="math inline">\(y \in
\mathbb{R}\)</span> and <span class="math inline">\(x \in \mathbb{R}^9\)</span> with density</p>
<p><span class="math display">\[
p(y,x) = \textsf{normal}(y \mid 0,3) \times \prod_{n=1}^9
\textsf{normal}(x_n \mid 0,\exp(y/2)).
\]</span></p>
<p>The probability contours are shaped like ten-dimensional funnels. The funnel’s neck is particularly sharp because of the exponential function applied to <span class="math inline">\(y\)</span>. A plot of the log marginal density of <span class="math inline">\(y\)</span> and the first dimension <span class="math inline">\(x_1\)</span> is shown in the following plot.</p>
<p>The marginal density of Neal’s funnel for the upper-level variable <span class="math inline">\(y\)</span> and one lower-level variable <span class="math inline">\(x_1\)</span> (see the text for the formula). The blue region has log density greater than -8, the yellow region density greater than -16, and the gray background a density less than -16.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="img/funnel.png" class="img-fluid figure-img"></p>
<figcaption>Neal’s funnel density</figcaption>
</figure>
</div>
<p>The funnel can be implemented directly in Stan as follows.</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode stan code-with-copy"><code class="sourceCode stan"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="kw">parameters</span> {</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>  <span class="dt">real</span> y;</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>  <span class="dt">vector</span>[<span class="dv">9</span>] x;</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="kw">model</span> {</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>  y ~ normal(<span class="dv">0</span>, <span class="dv">3</span>);</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>  x ~ normal(<span class="dv">0</span>, exp(y/<span class="dv">2</span>));</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>When the model is expressed this way, Stan has trouble sampling from the neck of the funnel, where <span class="math inline">\(y\)</span> is small and thus <span class="math inline">\(x\)</span> is constrained to be near 0. This is due to the fact that the density’s scale changes with <span class="math inline">\(y\)</span>, so that a step size that works well in the body will be too large for the neck, and a step size that works in the neck will be inefficient in the body. This can be seen in the following plot.</p>
<p>4000 draws are taken from a run of Stan’s sampler with default settings. Both plots are restricted to the shown window of <span class="math inline">\(x_1\)</span> and <span class="math inline">\(y\)</span> values; some draws fell outside of the displayed area as would be expected given the density. The samples are consistent with the marginal density <span class="math inline">\(p(y) = \textsf{normal}(y \mid 0,3)\)</span>, which has mean 0 and standard deviation 3.</p>
<p><img src="img/funnel-fit.png" class="img-fluid"></p>
<p>In this particular instance, because the analytic form of the density from which samples are drawn is known, the model can be converted to the following more efficient form.</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode stan code-with-copy"><code class="sourceCode stan"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="kw">parameters</span> {</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>  <span class="dt">real</span> y_raw;</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>  <span class="dt">vector</span>[<span class="dv">9</span>] x_raw;</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a><span class="kw">transformed parameters</span> {</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>  <span class="dt">real</span> y;</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>  <span class="dt">vector</span>[<span class="dv">9</span>] x;</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>  y = <span class="fl">3.0</span> * y_raw;</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>  x = exp(y/<span class="dv">2</span>) * x_raw;</span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a><span class="kw">model</span> {</span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>  y_raw ~ std_normal(); <span class="co">// implies y ~ normal(0, 3)</span></span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a>  x_raw ~ std_normal(); <span class="co">// implies x ~ normal(0, exp(y/2))</span></span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>In this second model, the parameters <code>x_raw</code> and <code>y_raw</code> are sampled as independent standard normals, which is easy for Stan. These are then transformed into samples from the funnel. In this case, the same transform may be used to define Monte Carlo samples directly based on independent standard normal samples; Markov chain Monte Carlo methods are not necessary. If such a reparameterization were used in Stan code, it is useful to provide a comment indicating what the distribution for the parameter implies for the distribution of the transformed parameter.</p>
</section>
<section id="reparameterizing-the-cauchy" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="reparameterizing-the-cauchy">Reparameterizing the Cauchy</h3>
<p>Sampling from heavy tailed distributions such as the Cauchy is difficult for Hamiltonian Monte Carlo, which operates within a Euclidean geometry.</p>
<p>The practical problem is that tail of the Cauchy requires a relatively large step size compared to the trunk. With a small step size, the No-U-Turn sampler requires many steps when starting in the tail of the distribution; with a large step size, there will be too much rejection in the central portion of the distribution. This problem may be mitigated by defining the Cauchy-distributed variable as the transform of a uniformly distributed variable using the Cauchy inverse cumulative distribution function.</p>
<p>Suppose a random variable of interest <span class="math inline">\(X\)</span> has a Cauchy distribution with location <span class="math inline">\(\mu\)</span> and scale <span class="math inline">\(\tau\)</span>, so that <span class="math inline">\(X \sim
\textsf{Cauchy}(\mu,\tau)\)</span>. The variable <span class="math inline">\(X\)</span> has a cumulative distribution function <span class="math inline">\(F_X:\mathbb{R} \rightarrow (0,1)\)</span> defined by <span class="math display">\[
F_X(x) = \frac{1}{\pi} \arctan \left( \frac{x - \mu}{\tau} \right) +
\frac{1}{2}.
\]</span> The inverse of the cumulative distribution function, <span class="math inline">\(F_X^{-1}:(0,1) \rightarrow \mathbb{R}\)</span>, is thus</p>
<p><span class="math display">\[
F^{-1}_X(y) = \mu + \tau \tan \left( \pi \left( y - \frac{1}{2} \right) \right).
\]</span> Thus if the random variable <span class="math inline">\(Y\)</span> has a unit uniform distribution, <span class="math inline">\(Y
\sim \textsf{uniform}(0,1)\)</span>, then <span class="math inline">\(F^{-1}_X(Y)\)</span> has a Cauchy distribution with location <span class="math inline">\(\mu\)</span> and scale <span class="math inline">\(\tau\)</span>, i.e., <span class="math inline">\(F^{-1}_X(Y) \sim
\textsf{Cauchy}(\mu,\tau)\)</span>.</p>
<p>Consider a Stan program involving a Cauchy-distributed parameter <code>beta</code>.</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode stan code-with-copy"><code class="sourceCode stan"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="kw">parameters</span> {</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>  <span class="dt">real</span> beta;</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>  <span class="co">// ...</span></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a><span class="kw">model</span> {</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>  beta ~ cauchy(mu, tau);</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>  <span class="co">// ...</span></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>This declaration of <code>beta</code> as a parameter may be replaced with a transformed parameter <code>beta</code> defined in terms of a uniform-distributed parameter <code>beta_unif</code>.</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode stan code-with-copy"><code class="sourceCode stan"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="kw">parameters</span> {</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>  <span class="dt">real</span>&lt;<span class="kw">lower</span>=-pi() / <span class="dv">2</span>, <span class="kw">upper</span>=pi() / <span class="dv">2</span>&gt; beta_unif;</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>  <span class="co">// ...</span></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a><span class="kw">transformed parameters</span> {</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>  <span class="dt">real</span> beta;</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>  beta = mu + tau * tan(beta_unif);  <span class="co">// beta ~ cauchy(mu, tau)</span></span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a><span class="kw">model</span> {</span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>  beta_unif ~ uniform(-pi() / <span class="dv">2</span>, pi() / <span class="dv">2</span>);  <span class="co">// not necessary</span></span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>  <span class="co">// ...</span></span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>It is more convenient in Stan to transform a uniform variable on <span class="math inline">\((-\pi/2, \pi/2)\)</span> than one on <span class="math inline">\((0,1)\)</span>. The Cauchy location and scale parameters, <code>mu</code> and <code>tau</code>, may be defined as data or may themselves be parameters. The variable <code>beta</code> could also be defined as a local variable if it does not need to be included in the sampler’s output.</p>
<p>The uniform distribution on <code>beta_unif</code> is defined explicitly in the model block, but it could be safely removed from the program without changing sampling behavior. This is because <span class="math inline">\(\log
\textsf{uniform}(\beta_{\textsf{unif}} \mid -\pi/2,\pi/2) =
-\log \pi\)</span> is a constant and Stan only needs the total log probability up to an additive constant. Stan will spend some time checking that that <code>beta_unif</code> is between <code>-pi() / 2</code> and <code>pi() / 2</code>, but this condition is guaranteed by the constraints in the declaration of <code>beta_unif</code>.</p>
</section>
<section id="reparameterizing-a-student-t-distribution" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="reparameterizing-a-student-t-distribution">Reparameterizing a Student-t distribution</h3>
<p>One thing that sometimes works when you’re having trouble with the heavy-tailedness of Student-t distributions is to use the gamma-mixture representation, which says that you can generate a Student-t distributed variable <span class="math inline">\(\beta\)</span>, <span class="math display">\[
\beta \sim \textsf{Student-t}(\nu, 0, 1),
\]</span> by first generating a gamma-distributed precision (inverse variance) <span class="math inline">\(\tau\)</span> according to <span class="math display">\[
\tau \sim \textsf{Gamma}(\nu/2, \nu/2),
\]</span> and then generating <span class="math inline">\(\beta\)</span> from the normal distribution, <span class="math display">\[
\beta \sim \textsf{normal}\left(0,\tau^{-\frac{1}{2}}\right).
\]</span></p>
<p>Because <span class="math inline">\(\tau\)</span> is precision, <span class="math inline">\(\tau^{-\frac{1}{2}}\)</span> is the scale (standard deviation), which is the parameterization used by Stan.</p>
<p>The marginal distribution of <span class="math inline">\(\beta\)</span> when you integrate out <span class="math inline">\(\tau\)</span> is <span class="math inline">\(\textsf{Student-t}(\nu, 0, 1)\)</span>, i.e., <span class="math display">\[
\textsf{Student-t}(\beta \mid \nu, 0, 1)
=
\int_0^{\infty}
\,
\textsf{normal}\left(\beta \middle| 0, \tau^{-0.5}\right)
\times
\textsf{Gamma}\left(\tau \middle| \nu/2, \nu/2\right)
\
\text{d} \tau.
\]</span></p>
<p>To go one step further, instead of defining a <span class="math inline">\(\beta\)</span> drawn from a normal with precision <span class="math inline">\(\tau\)</span>, define <span class="math inline">\(\alpha\)</span> to be drawn from a unit normal, <span class="math display">\[
\alpha \sim \textsf{normal}(0,1)
\]</span> and rescale by defining <span class="math display">\[
\beta = \alpha \, \tau^{-\frac{1}{2}}.
\]</span></p>
<p>Now suppose <span class="math inline">\(\mu = \beta x\)</span> is the product of <span class="math inline">\(\beta\)</span> with a regression predictor <span class="math inline">\(x\)</span>. Then the reparameterization <span class="math inline">\(\mu = \alpha
\tau^{-\frac{1}{2}} x\)</span> has the same distribution, but in the original, direct parameterization, <span class="math inline">\(\beta\)</span> has (potentially) heavy tails, whereas in the second, neither <span class="math inline">\(\tau\)</span> nor <span class="math inline">\(\alpha\)</span> have heavy tails.</p>
<p>To translate into Stan notation, this reparameterization replaces</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode stan code-with-copy"><code class="sourceCode stan"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="kw">parameters</span> {</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>  <span class="dt">real</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>&gt; nu;</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>  <span class="dt">real</span> beta;</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>  <span class="co">// ...</span></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a><span class="kw">model</span> {</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>  beta ~ student_t(nu, <span class="dv">0</span>, <span class="dv">1</span>);</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>  <span class="co">// ...</span></span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>with</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode stan code-with-copy"><code class="sourceCode stan"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="kw">parameters</span> {</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>  <span class="dt">real</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>&gt; nu;</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>  <span class="dt">real</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>&gt; tau;</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>  <span class="dt">real</span> alpha;</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>  <span class="co">// ...</span></span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a><span class="kw">transformed parameters</span> {</span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>  <span class="dt">real</span> beta;</span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>  beta = alpha / sqrt(tau);</span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>  <span class="co">// ...</span></span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a><span class="kw">model</span> {</span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a>  <span class="dt">real</span> half_nu;</span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a>  half_nu = <span class="fl">0.5</span> * nu;</span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a>  tau ~ gamma(half_nu, half_nu);</span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a>  alpha ~ std_normal();</span>
<span id="cb8-17"><a href="#cb8-17" aria-hidden="true" tabindex="-1"></a>  <span class="co">// ...</span></span>
<span id="cb8-18"><a href="#cb8-18" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Although set to <code>0</code> here, in most cases, the lower bound for the degrees of freedom parameter <code>nu</code> can be set to <code>1</code> or higher; when <code>nu</code> is 1, the result is a Cauchy distribution with fat tails and as <code>nu</code> approaches infinity, the Student-t distribution approaches a normal distribution. Thus the parameter <code>nu</code> characterizes the heaviness of the tails of the model.</p>
</section>
<section id="hierarchical-models-and-the-non-centered-parameterization" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="hierarchical-models-and-the-non-centered-parameterization">Hierarchical models and the non-centered parameterization</h3>
<p>Unfortunately, the usual situation in applied Bayesian modeling involves complex geometries and interactions that are not known analytically. Nevertheless, the non-centered parameterization can still be effective for separating parameters.</p>
<section id="centered-parameterization" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="centered-parameterization">Centered parameterization</h4>
<p>For example, a vectorized hierarchical model might draw a vector of coefficients <span class="math inline">\(\beta\)</span> with definitions as follows. The so-called centered parameterization is as follows.</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode stan code-with-copy"><code class="sourceCode stan"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="kw">parameters</span> {</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>  <span class="dt">real</span> mu_beta;</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>  <span class="dt">real</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>&gt; sigma_beta;</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>  <span class="dt">vector</span>[K] beta;</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>  <span class="co">// ...</span></span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a><span class="kw">model</span> {</span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>  beta ~ normal(mu_beta, sigma_beta);</span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>  <span class="co">// ...</span></span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Although not shown, a full model will have priors on both <code>mu_beta</code> and <code>sigma_beta</code> along with data modeled based on these coefficients. For instance, a standard binary logistic regression with data matrix <code>x</code> and binary outcome vector <code>y</code> would include a likelihood statement such as form <code>y ~ bernoulli_logit(x * beta)</code>, leading to an analytically intractable posterior.</p>
<p>A hierarchical model such as the above will suffer from the same kind of inefficiencies as Neal’s funnel, because the values of <code>beta</code>, <code>mu_beta</code> and <code>sigma_beta</code> are highly correlated in the posterior. The extremity of the correlation depends on the amount of data, with Neal’s funnel being the extreme with no data. In these cases, the non-centered parameterization, discussed in the next section, is preferable; when there is a lot of data, the centered parameterization is more efficient. See <span class="citation" data-cites="Betancourt-Girolami:2013">Betancourt and Girolami (<a href="#ref-Betancourt-Girolami:2013" role="doc-biblioref">2013</a>)</span> for more information on the effects of centering in hierarchical models fit with Hamiltonian Monte Carlo.</p>
</section>
</section>
<section id="non-centered-parameterization" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="non-centered-parameterization">Non-centered parameterization</h3>
<p>Sometimes the group-level effects do not constrain the hierarchical distribution tightly. Examples arise when there are not many groups, or when the inter-group variation is high. In such cases, hierarchical models can be made much more efficient by shifting the data’s correlation with the parameters to the hyperparameters. Similar to the funnel example, this will be much more efficient in terms of effective sample size when there is not much data (see <span class="citation" data-cites="Betancourt-Girolami:2013">Betancourt and Girolami (<a href="#ref-Betancourt-Girolami:2013" role="doc-biblioref">2013</a>)</span>), and in more extreme cases will be necessary to achieve convergence.</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode stan code-with-copy"><code class="sourceCode stan"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="kw">parameters</span> {</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>  <span class="dt">real</span> mu_beta;</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>  <span class="dt">real</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>&gt; sigma_beta;</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>  <span class="dt">vector</span>[K] beta_raw;</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>  <span class="co">// ...</span></span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a><span class="kw">transformed parameters</span> {</span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>  <span class="dt">vector</span>[K] beta;</span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>  <span class="co">// implies: beta ~ normal(mu_beta, sigma_beta)</span></span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a>  beta = mu_beta + sigma_beta * beta_raw;</span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a><span class="kw">model</span> {</span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a>  beta_raw ~ std_normal();</span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a>  <span class="co">// ...</span></span>
<span id="cb10-15"><a href="#cb10-15" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Any priors defined for <code>mu_beta</code> and <code>sigma_beta</code> remain as defined in the original model.</p>
<p>Alternatively, Stan’s <a href="https://mc-stan.org/docs/reference-manual/types.html#affinely-transformed-real">affine transform</a> can be used to decouple <code>sigma</code> and <code>beta</code>:</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode stan code-with-copy"><code class="sourceCode stan"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="kw">parameters</span> {</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>  <span class="dt">real</span> mu_beta;</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>  <span class="dt">real</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>&gt; sigma_beta;</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>  <span class="dt">vector</span>&lt;<span class="dt">offset</span>=mu_beta, <span class="dt">multiplier</span>=sigma_beta&gt;[K] beta;</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>  <span class="co">// ...</span></span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a><span class="kw">model</span> {</span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a>  beta ~ normal(mu_beta, sigma_beta);</span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a>  <span class="co">// ...</span></span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Reparameterization of hierarchical models is not limited to the normal distribution, although the normal distribution is the best candidate for doing so. In general, any distribution of parameters in the location-scale family is a good candidate for reparameterization. Let <span class="math inline">\(\beta = l + s\alpha\)</span> where <span class="math inline">\(l\)</span> is a location parameter and <span class="math inline">\(s\)</span> is a scale parameter. The parameter <span class="math inline">\(l\)</span> need not be the mean, <span class="math inline">\(s\)</span> need not be the standard deviation, and neither the mean nor the standard deviation need to exist. If <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span> are from the same distributional family but <span class="math inline">\(\alpha\)</span> has location zero and unit scale, while <span class="math inline">\(\beta\)</span> has location <span class="math inline">\(l\)</span> and scale <span class="math inline">\(s\)</span>, then that distribution is a location-scale distribution. Thus, if <span class="math inline">\(\alpha\)</span> were a parameter and <span class="math inline">\(\beta\)</span> were a transformed parameter, then a prior distribution from the location-scale family on <span class="math inline">\(\alpha\)</span> with location zero and unit scale implies a prior distribution on <span class="math inline">\(\beta\)</span> with location <span class="math inline">\(l\)</span> and scale <span class="math inline">\(s\)</span>. Doing so would reduce the dependence between <span class="math inline">\(\alpha\)</span>, <span class="math inline">\(l\)</span>, and <span class="math inline">\(s\)</span>.</p>
<p>There are several univariate distributions in the location-scale family, such as the Student t distribution, including its special cases of the Cauchy distribution (with one degree of freedom) and the normal distribution (with infinite degrees of freedom). As shown above, if <span class="math inline">\(\alpha\)</span> is distributed standard normal, then <span class="math inline">\(\beta\)</span> is distributed normal with mean <span class="math inline">\(\mu = l\)</span> and standard deviation <span class="math inline">\(\sigma = s\)</span>. The logistic, the double exponential, the generalized extreme value distributions, and the stable distribution are also in the location-scale family.</p>
<p>Also, if <span class="math inline">\(z\)</span> is distributed standard normal, then <span class="math inline">\(z^2\)</span> is distributed chi-squared with one degree of freedom. By summing the squares of <span class="math inline">\(K\)</span> independent standard normal variates, one can obtain a single variate that is distributed chi-squared with <span class="math inline">\(K\)</span> degrees of freedom. However, for large <span class="math inline">\(K\)</span>, the computational gains of this reparameterization may be overwhelmed by the computational cost of specifying <span class="math inline">\(K\)</span> primitive parameters just to obtain one transformed parameter to use in a model.</p>
</section>
<section id="multivariate-reparameterizations" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="multivariate-reparameterizations">Multivariate reparameterizations</h3>
<p>The benefits of reparameterization are not limited to univariate distributions. A parameter with a multivariate normal prior distribution is also an excellent candidate for reparameterization. Suppose you intend the prior for <span class="math inline">\(\beta\)</span> to be multivariate normal with mean vector <span class="math inline">\(\mu\)</span> and covariance matrix <span class="math inline">\(\Sigma\)</span>. Such a belief is reflected by the following code.</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode stan code-with-copy"><code class="sourceCode stan"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="kw">data</span> {</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>  <span class="dt">int</span>&lt;<span class="kw">lower</span>=<span class="dv">2</span>&gt; K;</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>  <span class="dt">vector</span>[K] mu;</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>  <span class="dt">cov_matrix</span>[K] Sigma;</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>  <span class="co">// ...</span></span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a><span class="kw">parameters</span> {</span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>  <span class="dt">vector</span>[K] beta;</span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a>  <span class="co">// ...</span></span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a><span class="kw">model</span> {</span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a>  beta ~ multi_normal(mu, Sigma);</span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a>  <span class="co">// ...</span></span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>In this case <code>mu</code> and <code>Sigma</code> are fixed data, but they could be unknown parameters, in which case their priors would be unaffected by a reparameterization of <code>beta</code>.</p>
<p>If <span class="math inline">\(\alpha\)</span> has the same dimensions as <span class="math inline">\(\beta\)</span> but the elements of <span class="math inline">\(\alpha\)</span> are independently and identically distributed standard normal such that <span class="math inline">\(\beta = \mu + L\alpha\)</span>, where <span class="math inline">\(LL^\top = \Sigma\)</span>, then <span class="math inline">\(\beta\)</span> is distributed multivariate normal with mean vector <span class="math inline">\(\mu\)</span> and covariance matrix <span class="math inline">\(\Sigma\)</span>. One choice for <span class="math inline">\(L\)</span> is the Cholesky factor of <span class="math inline">\(\Sigma\)</span>. Thus, the model above could be reparameterized as follows.</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode stan code-with-copy"><code class="sourceCode stan"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="kw">data</span> {</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>  <span class="dt">int</span>&lt;<span class="kw">lower</span>=<span class="dv">2</span>&gt; K;</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>  <span class="dt">vector</span>[K] mu;</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>  <span class="dt">cov_matrix</span>[K] Sigma;</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>  <span class="co">// ...</span></span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a><span class="kw">transformed data</span> {</span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a>  <span class="dt">matrix</span>[K, K] L;</span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a>  L = cholesky_decompose(Sigma);</span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a><span class="kw">parameters</span> {</span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a>  <span class="dt">vector</span>[K] alpha;</span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a>  <span class="co">// ...</span></span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb13-15"><a href="#cb13-15" aria-hidden="true" tabindex="-1"></a><span class="kw">transformed parameters</span> {</span>
<span id="cb13-16"><a href="#cb13-16" aria-hidden="true" tabindex="-1"></a>  <span class="dt">vector</span>[K] beta;</span>
<span id="cb13-17"><a href="#cb13-17" aria-hidden="true" tabindex="-1"></a>  beta = mu + L * alpha;</span>
<span id="cb13-18"><a href="#cb13-18" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb13-19"><a href="#cb13-19" aria-hidden="true" tabindex="-1"></a><span class="kw">model</span> {</span>
<span id="cb13-20"><a href="#cb13-20" aria-hidden="true" tabindex="-1"></a>  alpha ~ std_normal();</span>
<span id="cb13-21"><a href="#cb13-21" aria-hidden="true" tabindex="-1"></a>  <span class="co">// implies: beta ~ multi_normal(mu, Sigma)</span></span>
<span id="cb13-22"><a href="#cb13-22" aria-hidden="true" tabindex="-1"></a>  <span class="co">// ...</span></span>
<span id="cb13-23"><a href="#cb13-23" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>This reparameterization is more efficient for two reasons. First, it reduces dependence among the elements of <code>alpha</code> and second, it avoids the need to invert <code>Sigma</code> every time <code>multi_normal</code> is evaluated.</p>
<p>The Cholesky factor is also useful when a covariance matrix is decomposed into a correlation matrix that is multiplied from both sides by a diagonal matrix of standard deviations, where either the standard deviations or the correlations are unknown parameters. The Cholesky factor of the covariance matrix is equal to the product of a diagonal matrix of standard deviations and the Cholesky factor of the correlation matrix. Furthermore, the product of a diagonal matrix of standard deviations and a vector is equal to the elementwise product between the standard deviations and that vector. Thus, if for example the correlation matrix <code>Tau</code> were fixed data but the vector of standard deviations <code>sigma</code> were unknown parameters, then a reparameterization of <code>beta</code> in terms of <code>alpha</code> could be implemented as follows.</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode stan code-with-copy"><code class="sourceCode stan"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="kw">data</span> {</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>  <span class="dt">int</span>&lt;<span class="kw">lower</span>=<span class="dv">2</span>&gt; K;</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>  <span class="dt">vector</span>[K] mu;</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>  <span class="dt">corr_matrix</span>[K] Tau;</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>  <span class="co">// ...</span></span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a><span class="kw">transformed data</span> {</span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a>  <span class="dt">matrix</span>[K, K] L;</span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a>  L = cholesky_decompose(Tau);</span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a><span class="kw">parameters</span> {</span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a>  <span class="dt">vector</span>[K] alpha;</span>
<span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a>  <span class="dt">vector</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>&gt;[K] sigma;</span>
<span id="cb14-14"><a href="#cb14-14" aria-hidden="true" tabindex="-1"></a>  <span class="co">// ...</span></span>
<span id="cb14-15"><a href="#cb14-15" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb14-16"><a href="#cb14-16" aria-hidden="true" tabindex="-1"></a><span class="kw">transformed parameters</span> {</span>
<span id="cb14-17"><a href="#cb14-17" aria-hidden="true" tabindex="-1"></a>  <span class="dt">vector</span>[K] beta;</span>
<span id="cb14-18"><a href="#cb14-18" aria-hidden="true" tabindex="-1"></a>  <span class="co">// This equals mu + diag_matrix(sigma) * L * alpha;</span></span>
<span id="cb14-19"><a href="#cb14-19" aria-hidden="true" tabindex="-1"></a>  beta = mu + sigma .* (L * alpha);</span>
<span id="cb14-20"><a href="#cb14-20" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb14-21"><a href="#cb14-21" aria-hidden="true" tabindex="-1"></a><span class="kw">model</span> {</span>
<span id="cb14-22"><a href="#cb14-22" aria-hidden="true" tabindex="-1"></a>  sigma ~ cauchy(<span class="dv">0</span>, <span class="dv">5</span>);</span>
<span id="cb14-23"><a href="#cb14-23" aria-hidden="true" tabindex="-1"></a>  alpha ~ std_normal();</span>
<span id="cb14-24"><a href="#cb14-24" aria-hidden="true" tabindex="-1"></a>  <span class="co">// implies: beta ~ multi_normal(mu,</span></span>
<span id="cb14-25"><a href="#cb14-25" aria-hidden="true" tabindex="-1"></a>  <span class="co">//  diag_matrix(sigma) * L * L' * diag_matrix(sigma)))</span></span>
<span id="cb14-26"><a href="#cb14-26" aria-hidden="true" tabindex="-1"></a>  <span class="co">// ...</span></span>
<span id="cb14-27"><a href="#cb14-27" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>This reparameterization of a multivariate normal distribution in terms of standard normal variates can be extended to other multivariate distributions that can be conceptualized as contaminations of the multivariate normal, such as the multivariate Student t and the skew multivariate normal distribution.</p>
<p>A Wishart distribution can also be reparameterized in terms of standard normal variates and chi-squared variates. Let <span class="math inline">\(L\)</span> be the Cholesky factor of a <span class="math inline">\(K \times K\)</span> positive definite scale matrix <span class="math inline">\(S\)</span> and let <span class="math inline">\(\nu\)</span> be the degrees of freedom. If <span class="math display">\[
A = \begin{pmatrix}
\sqrt{c_{1}} &amp; 0            &amp; \cdots                &amp; 0 \\
z_{21}       &amp; \sqrt{c_{2}} &amp; \ddots                &amp; \vdots \\
\vdots       &amp; \ddots       &amp; \ddots                &amp; 0 \\
z_{K1}       &amp; \cdots       &amp; z_{K\left(K-1\right)} &amp; \sqrt{c_{K}}
\end{pmatrix},
\]</span> where each <span class="math inline">\(c_i\)</span> is distributed chi-squared with <span class="math inline">\(\nu - i + 1\)</span> degrees of freedom and each <span class="math inline">\(z_{ij}\)</span> is distributed standard normal, then <span class="math inline">\(W = LAA^{\top}L^{\top}\)</span> is distributed Wishart with scale matrix <span class="math inline">\(S = LL^{\top}\)</span> and degrees of freedom <span class="math inline">\(\nu\)</span>. Such a reparameterization can be implemented by the following Stan code:</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode stan code-with-copy"><code class="sourceCode stan"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="kw">data</span> {</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>  <span class="dt">int</span>&lt;<span class="kw">lower</span>=<span class="dv">1</span>&gt; N;</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>  <span class="dt">int</span>&lt;<span class="kw">lower</span>=<span class="dv">1</span>&gt; K;</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>  <span class="dt">int</span>&lt;<span class="kw">lower</span>=K + <span class="dv">2</span>&gt; nu</span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>  <span class="dt">matrix</span>[K, K] L; <span class="co">// Cholesky factor of scale matrix</span></span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>  <span class="dt">vector</span>[K] mu;</span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a>  <span class="dt">matrix</span>[N, K] y;</span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a>  <span class="co">// ...</span></span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a><span class="kw">parameters</span> {</span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a>  <span class="dt">vector</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>&gt;[K] c;</span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a>  <span class="dt">vector</span>[<span class="fl">0.5</span> * K * (K - <span class="dv">1</span>)] z;</span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a>  <span class="co">// ...</span></span>
<span id="cb15-14"><a href="#cb15-14" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb15-15"><a href="#cb15-15" aria-hidden="true" tabindex="-1"></a><span class="kw">model</span> {</span>
<span id="cb15-16"><a href="#cb15-16" aria-hidden="true" tabindex="-1"></a>  <span class="dt">matrix</span>[K, K] A;</span>
<span id="cb15-17"><a href="#cb15-17" aria-hidden="true" tabindex="-1"></a>  <span class="dt">int</span> count = <span class="dv">1</span>;</span>
<span id="cb15-18"><a href="#cb15-18" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (j <span class="cf">in</span> <span class="dv">1</span>:(K - <span class="dv">1</span>)) {</span>
<span id="cb15-19"><a href="#cb15-19" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> (i <span class="cf">in</span> (j + <span class="dv">1</span>):K) {</span>
<span id="cb15-20"><a href="#cb15-20" aria-hidden="true" tabindex="-1"></a>      A[i, j] = z[count];</span>
<span id="cb15-21"><a href="#cb15-21" aria-hidden="true" tabindex="-1"></a>      count += <span class="dv">1</span>;</span>
<span id="cb15-22"><a href="#cb15-22" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb15-23"><a href="#cb15-23" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span>:(j - <span class="dv">1</span>)) {</span>
<span id="cb15-24"><a href="#cb15-24" aria-hidden="true" tabindex="-1"></a>      A[i, j] = <span class="fl">0.0</span>;</span>
<span id="cb15-25"><a href="#cb15-25" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb15-26"><a href="#cb15-26" aria-hidden="true" tabindex="-1"></a>    A[j, j] = sqrt(c[j]);</span>
<span id="cb15-27"><a href="#cb15-27" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb15-28"><a href="#cb15-28" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span>:(K - <span class="dv">1</span>)) {</span>
<span id="cb15-29"><a href="#cb15-29" aria-hidden="true" tabindex="-1"></a>    A[i, K] = <span class="dv">0</span>;</span>
<span id="cb15-30"><a href="#cb15-30" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb15-31"><a href="#cb15-31" aria-hidden="true" tabindex="-1"></a>  A[K, K] = sqrt(c[K]);</span>
<span id="cb15-32"><a href="#cb15-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-33"><a href="#cb15-33" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span>:K) {</span>
<span id="cb15-34"><a href="#cb15-34" aria-hidden="true" tabindex="-1"></a>    c[i] ~ chi_square(nu - i + <span class="dv">1</span>);</span>
<span id="cb15-35"><a href="#cb15-35" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb15-36"><a href="#cb15-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-37"><a href="#cb15-37" aria-hidden="true" tabindex="-1"></a>  z ~ std_normal();</span>
<span id="cb15-38"><a href="#cb15-38" aria-hidden="true" tabindex="-1"></a>  <span class="co">// implies: L * A * A' * L' ~ wishart(nu, L * L')</span></span>
<span id="cb15-39"><a href="#cb15-39" aria-hidden="true" tabindex="-1"></a>  y ~ multi_normal_cholesky(mu, L * A);</span>
<span id="cb15-40"><a href="#cb15-40" aria-hidden="true" tabindex="-1"></a>  <span class="co">// ...</span></span>
<span id="cb15-41"><a href="#cb15-41" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>This reparameterization is more efficient for three reasons. First, it reduces dependence among the elements of <code>z</code> and second, it avoids the need to invert the covariance matrix, <span class="math inline">\(W\)</span> every time <code>wishart</code> is evaluated. Third, if <span class="math inline">\(W\)</span> is to be used with a multivariate normal distribution, you can pass <span class="math inline">\(L A\)</span> to the more efficient <code>multi_normal_cholesky</code> function, rather than passing <span class="math inline">\(W\)</span> to <code>multi_normal</code>.</p>
<p>If <span class="math inline">\(W\)</span> is distributed Wishart with scale matrix <span class="math inline">\(S\)</span> and degrees of freedom <span class="math inline">\(\nu\)</span>, then <span class="math inline">\(W^{-1}\)</span> is distributed inverse Wishart with inverse scale matrix <span class="math inline">\(S^{-1}\)</span> and degrees of freedom <span class="math inline">\(\nu\)</span>. Thus, the previous result can be used to reparameterize the inverse Wishart distribution. Since <span class="math inline">\(W = L A A^{\top} L^{\top}\)</span>, <span class="math inline">\(W^{-1} = L^{{\top}^{-1}} A^{{\top}^{-1}} A^{-1} L^{-1}\)</span>, where all four inverses exist, but <span class="math inline">\(L^{{-1}^{\top}} = L^{{\top}^{-1}}\)</span> and <span class="math inline">\(A^{{-1}^{\top}} = A^{{\top}^{-1}}\)</span>. We can slightly modify the above Stan code for this case:</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode stan code-with-copy"><code class="sourceCode stan"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="kw">data</span> {</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>  <span class="dt">int</span>&lt;<span class="kw">lower</span>=<span class="dv">1</span>&gt; K;</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>  <span class="dt">int</span>&lt;<span class="kw">lower</span>=K + <span class="dv">2</span>&gt; nu</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>  <span class="dt">matrix</span>[K, K] L; <span class="co">// Cholesky factor of scale matrix</span></span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>  <span class="co">// ...</span></span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a><span class="kw">transformed data</span> {</span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a>  <span class="dt">matrix</span>[K, K] eye;</span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a>  <span class="dt">matrix</span>[K, K] L_inv;</span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (j <span class="cf">in</span> <span class="dv">1</span>:K) {</span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span>:K) {</span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a>      eye[i, j] = <span class="fl">0.0</span>;</span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a>    eye[j, j] = <span class="fl">1.0</span>;</span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb16-16"><a href="#cb16-16" aria-hidden="true" tabindex="-1"></a>  L_inv = mdivide_left_tri_low(L, eye);</span>
<span id="cb16-17"><a href="#cb16-17" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb16-18"><a href="#cb16-18" aria-hidden="true" tabindex="-1"></a><span class="kw">parameters</span> {</span>
<span id="cb16-19"><a href="#cb16-19" aria-hidden="true" tabindex="-1"></a>  <span class="dt">vector</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>&gt;[K] c;</span>
<span id="cb16-20"><a href="#cb16-20" aria-hidden="true" tabindex="-1"></a>  <span class="dt">vector</span>[<span class="fl">0.5</span> * K * (K - <span class="dv">1</span>)] z;</span>
<span id="cb16-21"><a href="#cb16-21" aria-hidden="true" tabindex="-1"></a>  <span class="co">// ...</span></span>
<span id="cb16-22"><a href="#cb16-22" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb16-23"><a href="#cb16-23" aria-hidden="true" tabindex="-1"></a><span class="kw">model</span> {</span>
<span id="cb16-24"><a href="#cb16-24" aria-hidden="true" tabindex="-1"></a>  <span class="dt">matrix</span>[K, K] A;</span>
<span id="cb16-25"><a href="#cb16-25" aria-hidden="true" tabindex="-1"></a>  <span class="dt">matrix</span>[K, K] A_inv_L_inv;</span>
<span id="cb16-26"><a href="#cb16-26" aria-hidden="true" tabindex="-1"></a>  <span class="dt">int</span> count;</span>
<span id="cb16-27"><a href="#cb16-27" aria-hidden="true" tabindex="-1"></a>  count = <span class="dv">1</span>;</span>
<span id="cb16-28"><a href="#cb16-28" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (j <span class="cf">in</span> <span class="dv">1</span>:(K - <span class="dv">1</span>)) {</span>
<span id="cb16-29"><a href="#cb16-29" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> (i <span class="cf">in</span> (j + <span class="dv">1</span>):K) {</span>
<span id="cb16-30"><a href="#cb16-30" aria-hidden="true" tabindex="-1"></a>      A[i, j] = z[count];</span>
<span id="cb16-31"><a href="#cb16-31" aria-hidden="true" tabindex="-1"></a>      count += <span class="dv">1</span>;</span>
<span id="cb16-32"><a href="#cb16-32" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb16-33"><a href="#cb16-33" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span>:(j - <span class="dv">1</span>)) {</span>
<span id="cb16-34"><a href="#cb16-34" aria-hidden="true" tabindex="-1"></a>      A[i, j] = <span class="fl">0.0</span>;</span>
<span id="cb16-35"><a href="#cb16-35" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb16-36"><a href="#cb16-36" aria-hidden="true" tabindex="-1"></a>    A[j, j] = sqrt(c[j]);</span>
<span id="cb16-37"><a href="#cb16-37" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb16-38"><a href="#cb16-38" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span>:(K - <span class="dv">1</span>)) {</span>
<span id="cb16-39"><a href="#cb16-39" aria-hidden="true" tabindex="-1"></a>    A[i, K] = <span class="dv">0</span>;</span>
<span id="cb16-40"><a href="#cb16-40" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb16-41"><a href="#cb16-41" aria-hidden="true" tabindex="-1"></a>  A[K, K] = sqrt(c[K]);</span>
<span id="cb16-42"><a href="#cb16-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-43"><a href="#cb16-43" aria-hidden="true" tabindex="-1"></a>  A_inv_L_inv = mdivide_left_tri_low(A, L_inv);</span>
<span id="cb16-44"><a href="#cb16-44" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span>:K) {</span>
<span id="cb16-45"><a href="#cb16-45" aria-hidden="true" tabindex="-1"></a>    c[i] ~ chi_square(nu - i + <span class="dv">1</span>);</span>
<span id="cb16-46"><a href="#cb16-46" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb16-47"><a href="#cb16-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-48"><a href="#cb16-48" aria-hidden="true" tabindex="-1"></a>  z ~ std_normal(); <span class="co">// implies: crossprod(A_inv_L_inv) ~</span></span>
<span id="cb16-49"><a href="#cb16-49" aria-hidden="true" tabindex="-1"></a>  <span class="co">// inv_wishart(nu, L_inv' * L_inv)</span></span>
<span id="cb16-50"><a href="#cb16-50" aria-hidden="true" tabindex="-1"></a>  <span class="co">// ...</span></span>
<span id="cb16-51"><a href="#cb16-51" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Another candidate for reparameterization is the Dirichlet distribution with all <span class="math inline">\(K\)</span> shape parameters equal. <span class="citation" data-cites="ZyczkowskiSommers:2001">Zyczkowski and Sommers (<a href="#ref-ZyczkowskiSommers:2001" role="doc-biblioref">2001</a>)</span> shows that if <span class="math inline">\(\theta_i\)</span> is equal to the sum of <span class="math inline">\(\beta\)</span> independent squared standard normal variates and <span class="math inline">\(\rho_i = \frac{\theta_i}{\sum \theta_i}\)</span>, then the <span class="math inline">\(K\)</span>-vector <span class="math inline">\(\rho\)</span> is distributed Dirichlet with all shape parameters equal to <span class="math inline">\(\frac{\beta}{2}\)</span>. In particular, if <span class="math inline">\(\beta = 2\)</span>, then <span class="math inline">\(\rho\)</span> is uniformly distributed on the unit simplex. Thus, we can make <span class="math inline">\(\rho\)</span> be a transformed parameter to reduce dependence, as in:</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode stan code-with-copy"><code class="sourceCode stan"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="kw">data</span> {</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>  <span class="dt">int</span>&lt;<span class="kw">lower</span>=<span class="dv">1</span>&gt; beta;</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>  <span class="co">// ...</span></span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a><span class="kw">parameters</span> {</span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>  <span class="dt">array</span>[K] <span class="dt">vector</span>[beta] z;</span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a>  <span class="co">// ...</span></span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a><span class="kw">transformed parameters</span> {</span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a>  <span class="dt">simplex</span>[K] rho;</span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (k <span class="cf">in</span> <span class="dv">1</span>:K) {</span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a>    rho[k] = dot_self(z[k]); <span class="co">// sum-of-squares</span></span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb17-14"><a href="#cb17-14" aria-hidden="true" tabindex="-1"></a>  rho = rho / sum(rho);</span>
<span id="cb17-15"><a href="#cb17-15" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb17-16"><a href="#cb17-16" aria-hidden="true" tabindex="-1"></a><span class="kw">model</span> {</span>
<span id="cb17-17"><a href="#cb17-17" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (k <span class="cf">in</span> <span class="dv">1</span>:K) {</span>
<span id="cb17-18"><a href="#cb17-18" aria-hidden="true" tabindex="-1"></a>    z[k] ~ std_normal();</span>
<span id="cb17-19"><a href="#cb17-19" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb17-20"><a href="#cb17-20" aria-hidden="true" tabindex="-1"></a>  <span class="co">// implies: rho ~ dirichlet(0.5 * beta * ones)</span></span>
<span id="cb17-21"><a href="#cb17-21" aria-hidden="true" tabindex="-1"></a>  <span class="co">// ...</span></span>
<span id="cb17-22"><a href="#cb17-22" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
</section>
<section id="vectorization" class="level2">
<h2 class="anchored" data-anchor-id="vectorization">Vectorization</h2>
<section id="gradient-bottleneck" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="gradient-bottleneck">Gradient bottleneck</h3>
<p>Stan spends the vast majority of its time computing the gradient of the log probability function, making gradients the obvious target for optimization. Stan’s gradient calculations with algorithmic differentiation require a template expression to be allocated and constructed for each subexpression of a Stan program involving parameters or transformed parameters.<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a> This section defines optimization strategies based on vectorizing these subexpressions to reduce the work done during algorithmic differentiation.</p>
</section>
<section id="vectorizing-summations" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="vectorizing-summations">Vectorizing summations</h3>
<p>Because of the gradient bottleneck described in the previous section, it is more efficient to collect a sequence of summands into a vector or array and then apply the <code>sum()</code> operation than it is to continually increment a variable by assignment and addition. For example, consider the following code snippet, where <code>foo()</code> is some operation that depends on <code>n</code>.</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode stan code-with-copy"><code class="sourceCode stan"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (n <span class="cf">in</span> <span class="dv">1</span>:N) {</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>  total += foo(n,...);</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>This code has to create intermediate representations for each of the <code>N</code> summands.</p>
<p>A faster alternative is to copy the values into a vector, then apply the <code>sum()</code> operator, as in the following refactoring.</p>
<div class="sourceCode" id="cb19"><pre class="sourceCode stan code-with-copy"><code class="sourceCode stan"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>{</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>  <span class="dt">vector</span>[N] summands;</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (n <span class="cf">in</span> <span class="dv">1</span>:N) {</span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>    summands[n] = foo(n,...);</span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a>  total = sum(summands);</span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Syntactically, the replacement is a statement block delineated by curly brackets (<code>{</code>, <code>}</code>), starting with the definition of the local variable <code>summands</code>.</p>
<p>Even though it involves extra work to allocate the <code>summands</code> vector and copy <code>N</code> values into it, the savings in differentiation more than make up for it. Perhaps surprisingly, it will also use substantially less memory overall than incrementing <code>total</code> within the loop.</p>
</section>
<section id="vectorization-through-matrix-operations" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="vectorization-through-matrix-operations">Vectorization through matrix operations</h3>
<p>The following program directly encodes a linear regression with fixed unit noise using a two-dimensional array <code>x</code> of predictors, an array <code>y</code> of outcomes, and an array <code>beta</code> of regression coefficients.</p>
<div class="sourceCode" id="cb20"><pre class="sourceCode stan code-with-copy"><code class="sourceCode stan"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="kw">data</span> {</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>  <span class="dt">int</span>&lt;<span class="kw">lower</span>=<span class="dv">1</span>&gt; K;</span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>  <span class="dt">int</span>&lt;<span class="kw">lower</span>=<span class="dv">1</span>&gt; N;</span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a>  <span class="dt">array</span>[K, N] <span class="dt">real</span> x;</span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a>  <span class="dt">array</span>[N] <span class="dt">real</span> y;</span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a><span class="kw">parameters</span> {</span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a>  <span class="dt">array</span>[K] <span class="dt">real</span> beta;</span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true" tabindex="-1"></a><span class="kw">model</span> {</span>
<span id="cb20-11"><a href="#cb20-11" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (n <span class="cf">in</span> <span class="dv">1</span>:N) {</span>
<span id="cb20-12"><a href="#cb20-12" aria-hidden="true" tabindex="-1"></a>    <span class="dt">real</span> gamma = <span class="dv">0</span>;</span>
<span id="cb20-13"><a href="#cb20-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> (k <span class="cf">in</span> <span class="dv">1</span>:K) {</span>
<span id="cb20-14"><a href="#cb20-14" aria-hidden="true" tabindex="-1"></a>      gamma += x[n, k] * beta[k];</span>
<span id="cb20-15"><a href="#cb20-15" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb20-16"><a href="#cb20-16" aria-hidden="true" tabindex="-1"></a>    y[n] ~ normal(gamma, <span class="dv">1</span>);</span>
<span id="cb20-17"><a href="#cb20-17" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb20-18"><a href="#cb20-18" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>The following model computes the same log probability function as the previous model, even supporting the same input files for data and initialization.</p>
<div class="sourceCode" id="cb21"><pre class="sourceCode stan code-with-copy"><code class="sourceCode stan"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="kw">data</span> {</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>  <span class="dt">int</span>&lt;<span class="kw">lower</span>=<span class="dv">1</span>&gt; K;</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a>  <span class="dt">int</span>&lt;<span class="kw">lower</span>=<span class="dv">1</span>&gt; N;</span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a>  <span class="dt">array</span>[N] <span class="dt">vector</span>[K] x;</span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a>  <span class="dt">array</span>[N] <span class="dt">real</span> y;</span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a><span class="kw">parameters</span> {</span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a>  <span class="dt">vector</span>[K] beta;</span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a><span class="kw">model</span> {</span>
<span id="cb21-11"><a href="#cb21-11" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (n <span class="cf">in</span> <span class="dv">1</span>:N) {</span>
<span id="cb21-12"><a href="#cb21-12" aria-hidden="true" tabindex="-1"></a>    y[n] ~ normal(dot_product(x[n], beta), <span class="dv">1</span>);</span>
<span id="cb21-13"><a href="#cb21-13" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb21-14"><a href="#cb21-14" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Although it produces equivalent results, the dot product should not be replaced with a transpose and multiply, as in</p>
<div class="sourceCode" id="cb22"><pre class="sourceCode stan code-with-copy"><code class="sourceCode stan"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>y[n] ~ normal(x[n]' * beta, <span class="dv">1</span>);</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>The relative inefficiency of the transpose and multiply approach is that the transposition operator allocates a new vector into which the result of the transposition is copied. This consumes both time and memory.<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a></p>
<p>The inefficiency of transposition could itself be mitigated by reordering the product and pulling the transposition out of the loop, as follows.</p>
<div class="sourceCode" id="cb23"><pre class="sourceCode stan code-with-copy"><code class="sourceCode stan"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="co">// ...</span></span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a><span class="kw">transformed parameters</span> {</span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a>  <span class="dt">row_vector</span>[K] beta_t;</span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a>  beta_t = beta';</span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a><span class="kw">model</span> {</span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (n <span class="cf">in</span> <span class="dv">1</span>:N) {</span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a>    y[n] ~ normal(beta_t * x[n], <span class="dv">1</span>);</span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb23-10"><a href="#cb23-10" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>The problem with transposition could be completely solved by directly encoding the <code>x</code> as a row vector, as in the following example.</p>
<div class="sourceCode" id="cb24"><pre class="sourceCode stan code-with-copy"><code class="sourceCode stan"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="kw">data</span> {</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>  <span class="co">// ...</span></span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a>  <span class="dt">array</span>[N] <span class="dt">row_vector</span>[K] x;</span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>  <span class="co">// ...</span></span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a><span class="kw">parameters</span> {</span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a>  <span class="dt">vector</span>[K] beta;</span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a><span class="kw">model</span> {</span>
<span id="cb24-10"><a href="#cb24-10" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (n <span class="cf">in</span> <span class="dv">1</span>:N) {</span>
<span id="cb24-11"><a href="#cb24-11" aria-hidden="true" tabindex="-1"></a>    y[n] ~ normal(x[n] * beta, <span class="dv">1</span>);</span>
<span id="cb24-12"><a href="#cb24-12" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb24-13"><a href="#cb24-13" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Declaring the data as a matrix and then computing all the predictors at once using matrix multiplication is more efficient still, as in the example discussed in the next section.</p>
<p>Having said all this, the most efficient way to code this model is with direct matrix multiplication, as in</p>
<div class="sourceCode" id="cb25"><pre class="sourceCode stan code-with-copy"><code class="sourceCode stan"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="kw">data</span> {</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>  <span class="dt">matrix</span>[N, K] x;</span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a>  <span class="dt">vector</span>[N] y;</span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a><span class="kw">parameters</span> {</span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a>  <span class="dt">vector</span>[K] beta;</span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb25-8"><a href="#cb25-8" aria-hidden="true" tabindex="-1"></a><span class="kw">model</span> {</span>
<span id="cb25-9"><a href="#cb25-9" aria-hidden="true" tabindex="-1"></a>  y ~ normal(x * beta, <span class="dv">1</span>);</span>
<span id="cb25-10"><a href="#cb25-10" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>In general, encapsulated single operations that do the work of loops will be more efficient in their encapsulated forms. Rather than performing a sequence of row-vector/vector multiplications, it is better to encapsulate it as a single matrix/vector multiplication.</p>
</section>
<section id="vectorized-probability-functions" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="vectorized-probability-functions">Vectorized probability functions</h3>
<p>The final and most efficient version replaces the loops and transformed parameters by using the vectorized form of the normal probability function, as in the following example.</p>
<div class="sourceCode" id="cb26"><pre class="sourceCode stan code-with-copy"><code class="sourceCode stan"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="kw">data</span> {</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>  <span class="dt">int</span>&lt;<span class="kw">lower</span>=<span class="dv">1</span>&gt; K;</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a>  <span class="dt">int</span>&lt;<span class="kw">lower</span>=<span class="dv">1</span>&gt; N;</span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a>  <span class="dt">matrix</span>[N, K] x;</span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a>  <span class="dt">vector</span>[N] y;</span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb26-7"><a href="#cb26-7" aria-hidden="true" tabindex="-1"></a><span class="kw">parameters</span> {</span>
<span id="cb26-8"><a href="#cb26-8" aria-hidden="true" tabindex="-1"></a>  <span class="dt">vector</span>[K] beta;</span>
<span id="cb26-9"><a href="#cb26-9" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb26-10"><a href="#cb26-10" aria-hidden="true" tabindex="-1"></a><span class="kw">model</span> {</span>
<span id="cb26-11"><a href="#cb26-11" aria-hidden="true" tabindex="-1"></a>  y ~ normal(x * beta, <span class="dv">1</span>);</span>
<span id="cb26-12"><a href="#cb26-12" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>The variables are all declared as either matrix or vector types. The result of the matrix-vector multiplication <code>x * beta</code> in the model block is a vector of the same length as <code>y</code>.</p>
<p>The probability function documentation in the function reference manual indicates which of Stan’s probability functions support vectorization; see the function reference manual for full details. Vectorized probability functions accept either vector or scalar inputs for all arguments, with the only restriction being that all vector arguments are the same dimensionality. In the example above, <code>y</code> is a vector of size <code>N</code>, <code>x * beta</code> is a vector of size <code>N</code>, and <code>1</code> is a scalar.</p>
</section>
<section id="reshaping-data-for-vectorization" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="reshaping-data-for-vectorization">Reshaping data for vectorization</h3>
<p>Sometimes data does not arrive in a shape that is ideal for vectorization, but can be put into such shape with some munging (either inside Stan’s transformed data block or outside).</p>
<p>John Hall provided a simple example on the Stan users group. Simplifying notation a bit, the original model had a sampling statement in a loop, as follows.</p>
<div class="sourceCode" id="cb27"><pre class="sourceCode stan code-with-copy"><code class="sourceCode stan"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (n <span class="cf">in</span> <span class="dv">1</span>:N) {</span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>  y[n] ~ normal(mu[ii[n]], sigma);</span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>The brute force vectorization would build up a mean vector and then vectorize all at once.</p>
<div class="sourceCode" id="cb28"><pre class="sourceCode stan code-with-copy"><code class="sourceCode stan"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>{</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>  <span class="dt">vector</span>[N] mu_ii;</span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (n <span class="cf">in</span> <span class="dv">1</span>:N) {</span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a>    mu_ii[n] = mu[ii[n]];</span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a>  y ~ normal(mu_ii, sigma);</span>
<span id="cb28-7"><a href="#cb28-7" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>If there aren’t many levels (values <code>ii[n]</code> can take), then it behooves us to reorganize the data by group in a case like this. Rather than having a single observation vector <code>y</code>, there are K of them. And because Stan doesn’t support ragged arrays, it means K declarations. For instance, with 5 levels, we have</p>
<div class="sourceCode" id="cb29"><pre class="sourceCode stan code-with-copy"><code class="sourceCode stan"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a>y_1 ~ normal(mu[<span class="dv">1</span>], sigma);</span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a><span class="co">// ...</span></span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a>y_5 ~ normal(mu[<span class="dv">5</span>], sigma);</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>This way, both the <code>mu</code> and <code>sigma</code> parameters are shared. Which way works out to be more efficient will depend on the shape of the data; if the sizes are small, the simple vectorization may be faster, but for moderate to large sized groups, the full expansion should be faster.</p>
</section>
</section>
<section id="exploiting-sufficient-statistics" class="level2">
<h2 class="anchored" data-anchor-id="exploiting-sufficient-statistics">Exploiting sufficient statistics</h2>
<p>In some cases, models can be recoded to exploit sufficient statistics in estimation. This can lead to large efficiency gains compared to an expanded model. This section provides examples for Bernoulli and normal distributions, but the same approach can be applied to other members of the exponential family.</p>
<section id="bernoulli-sufficient-statistics" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="bernoulli-sufficient-statistics">Bernoulli sufficient statistics</h3>
<p>Consider the following Bernoulli sampling model.</p>
<div class="sourceCode" id="cb30"><pre class="sourceCode stan code-with-copy"><code class="sourceCode stan"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="kw">data</span> {</span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a>  <span class="dt">int</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>&gt; N;</span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a>  <span class="dt">array</span>[N] <span class="dt">int</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>, <span class="kw">upper</span>=<span class="dv">1</span>&gt; y;</span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a>  <span class="dt">real</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>&gt; alpha;</span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a>  <span class="dt">real</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>&gt; beta;</span>
<span id="cb30-6"><a href="#cb30-6" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb30-7"><a href="#cb30-7" aria-hidden="true" tabindex="-1"></a><span class="kw">parameters</span> {</span>
<span id="cb30-8"><a href="#cb30-8" aria-hidden="true" tabindex="-1"></a>  <span class="dt">real</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>, <span class="kw">upper</span>=<span class="dv">1</span>&gt; theta;</span>
<span id="cb30-9"><a href="#cb30-9" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb30-10"><a href="#cb30-10" aria-hidden="true" tabindex="-1"></a><span class="kw">model</span> {</span>
<span id="cb30-11"><a href="#cb30-11" aria-hidden="true" tabindex="-1"></a>  theta ~ beta(alpha, beta);</span>
<span id="cb30-12"><a href="#cb30-12" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (n <span class="cf">in</span> <span class="dv">1</span>:N) {</span>
<span id="cb30-13"><a href="#cb30-13" aria-hidden="true" tabindex="-1"></a>    y[n] ~ bernoulli(theta);</span>
<span id="cb30-14"><a href="#cb30-14" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb30-15"><a href="#cb30-15" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>In this model, the sum of positive outcomes in <code>y</code> is a sufficient statistic for the chance of success <code>theta</code>. The model may be recoded using the binomial distribution as follows.</p>
<div class="sourceCode" id="cb31"><pre class="sourceCode stan code-with-copy"><code class="sourceCode stan"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a>theta ~ beta(alpha, beta);</span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>sum(y) ~ binomial(N, theta);</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Because truth is represented as one and falsehood as zero, the sum <code>sum(y)</code> of a binary vector <code>y</code> is equal to the number of positive outcomes out of a total of <code>N</code> trials.</p>
<p>This can be generalized to other discrete cases (one wouldn’t expect continuous observations to be duplicated if they are random). Suppose there are only <span class="math inline">\(K\)</span> possible discrete outcomes, <span class="math inline">\(z_1, \dotsc, z_K\)</span>, but there are <span class="math inline">\(N\)</span> observations, where <span class="math inline">\(N\)</span> is much larger than <span class="math inline">\(K\)</span>. If <span class="math inline">\(f_k\)</span> is the frequency of outcome <span class="math inline">\(z_k\)</span>, then the entire likelihood with distribution <code>foo</code> can be coded as follows.</p>
<div class="sourceCode" id="cb32"><pre class="sourceCode stan code-with-copy"><code class="sourceCode stan"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (k <span class="cf">in</span> <span class="dv">1</span>:K) {</span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a>  <span class="kw">target +=</span> f[k] * foo_lpmf(z[k] | ...);</span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>where the ellipses are the parameters of the log probability mass function for distribution <code>foo</code> (there’s no distribution called “foo”; this is just a placeholder for any discrete distribution name).</p>
<p>The resulting program looks like a “weighted” regression, but here the weights <code>f[k]</code> are counts and thus sufficient statistics for the PMF and simply amount to an alternative, more efficient coding of the same likelihood. For efficiency, the frequencies <code>f[k]</code> should be counted once in the transformed data block and stored.</p>
<p>The same trick works for combining multiple binomial observations.</p>
</section>
<section id="normal-sufficient-statistics" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="normal-sufficient-statistics">Normal sufficient statistics</h3>
<p>Consider the following Stan model for fitting a normal distribution to data.</p>
<div class="sourceCode" id="cb33"><pre class="sourceCode stan code-with-copy"><code class="sourceCode stan"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="kw">data</span> {</span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>  <span class="dt">int</span> N;</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a>  <span class="dt">vector</span>[N] y;</span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a><span class="kw">parameters</span> {</span>
<span id="cb33-6"><a href="#cb33-6" aria-hidden="true" tabindex="-1"></a>  <span class="dt">real</span> mu;</span>
<span id="cb33-7"><a href="#cb33-7" aria-hidden="true" tabindex="-1"></a>  <span class="dt">real</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>&gt; sigma;</span>
<span id="cb33-8"><a href="#cb33-8" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb33-9"><a href="#cb33-9" aria-hidden="true" tabindex="-1"></a><span class="kw">model</span> {</span>
<span id="cb33-10"><a href="#cb33-10" aria-hidden="true" tabindex="-1"></a>  y ~ normal(mu, sigma);</span>
<span id="cb33-11"><a href="#cb33-11" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>With the vectorized form used for <code>y</code>, Stan is clever enough to only evaluate <code>log(sigma)</code> once, but it still has to evaluate the normal for all of <code>y[1]</code> to <code>y[N]</code>, which involves adding up all the squared differences from the mean and then dividing by <code>sigma</code> squared.</p>
<p>An equivalent density to the one above (up to normalizing constants that do not depend on parameters), is given in the following Stan program.</p>
<div class="sourceCode" id="cb34"><pre class="sourceCode stan code-with-copy"><code class="sourceCode stan"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="kw">data</span> {</span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a>  <span class="dt">int</span> N;</span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a>  <span class="dt">vector</span>[N] y;</span>
<span id="cb34-4"><a href="#cb34-4" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb34-5"><a href="#cb34-5" aria-hidden="true" tabindex="-1"></a><span class="kw">transformed data</span> {</span>
<span id="cb34-6"><a href="#cb34-6" aria-hidden="true" tabindex="-1"></a>  <span class="dt">real</span> mean_y = mean(y);</span>
<span id="cb34-7"><a href="#cb34-7" aria-hidden="true" tabindex="-1"></a>  <span class="dt">real</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>&gt; var_y = variance(y);</span>
<span id="cb34-8"><a href="#cb34-8" aria-hidden="true" tabindex="-1"></a>  <span class="dt">real</span> nm1_over2 = <span class="fl">0.5</span> * (N - <span class="dv">1</span>);</span>
<span id="cb34-9"><a href="#cb34-9" aria-hidden="true" tabindex="-1"></a>  <span class="dt">real</span> sqrt_N = sqrt(N);</span>
<span id="cb34-10"><a href="#cb34-10" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb34-11"><a href="#cb34-11" aria-hidden="true" tabindex="-1"></a><span class="kw">parameters</span> {</span>
<span id="cb34-12"><a href="#cb34-12" aria-hidden="true" tabindex="-1"></a>  <span class="dt">real</span> mu;</span>
<span id="cb34-13"><a href="#cb34-13" aria-hidden="true" tabindex="-1"></a>  <span class="dt">real</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>&gt; sigma;</span>
<span id="cb34-14"><a href="#cb34-14" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb34-15"><a href="#cb34-15" aria-hidden="true" tabindex="-1"></a><span class="kw">model</span> {</span>
<span id="cb34-16"><a href="#cb34-16" aria-hidden="true" tabindex="-1"></a>  mean_y ~ normal(mu, sigma / sqrt_N);</span>
<span id="cb34-17"><a href="#cb34-17" aria-hidden="true" tabindex="-1"></a>  var_y ~ gamma(nm1_over2, nm1_over2 / sigma^<span class="dv">2</span>);</span>
<span id="cb34-18"><a href="#cb34-18" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>The data and parameters are the same in this program as in the first. The second version adds a transformed data block to compute the mean and variance of the data, which are the sufficient statistics here. These are stored along with two other useful constants. Then the program can define distributions over the mean and variance, both of which are scalars here.</p>
<p>The original Stan program and this one define the same model in the sense that they define the same log density up to a constant additive term that does not depend on the parameters. The priors on <code>mu</code> and <code>sigma</code> are both improper, but proper priors could be added as additional statements in the model block without affecting the sufficiency.</p>
<p>This transform explicitly relies on aggregating the data. Using this trick on parameters leads to more computation than just computing the normal log density, even before accounting for the non-linear change of variables in the variance.</p>
</section>
<section id="poisson-sufficient-statistics" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="poisson-sufficient-statistics">Poisson sufficient statistics</h3>
<p>The Poisson distribution is the easiest case, because the sum of observations is sufficient. Specifically, we can replace</p>
<div class="sourceCode" id="cb35"><pre class="sourceCode stan code-with-copy"><code class="sourceCode stan"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a>y ~ poisson(lambda);</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>with</p>
<div class="sourceCode" id="cb36"><pre class="sourceCode stan code-with-copy"><code class="sourceCode stan"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a>sum(y) ~ poisson(size(y) * lambda);</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>This will work even if <code>y</code> is a parameter vector because no Jacobian adjustment is required for summation.</p>
</section>
</section>
<section id="aggregating-common-subexpressions" class="level2">
<h2 class="anchored" data-anchor-id="aggregating-common-subexpressions">Aggregating common subexpressions</h2>
<p>If an expression is calculated once, the value should be saved and reused wherever possible. That is, rather than using <code>exp(theta)</code> in multiple places, declare a local variable to store its value and reuse the local variable.</p>
<p>Another case that may not be so obvious is with two multilevel parameters, say <code>a[ii[n]] + b[jj[n]]</code>. If <code>a</code> and <code>b</code> are small (i.e., do not have many levels), then a table <code>a_b</code> of their sums can be created, with</p>
<div class="sourceCode" id="cb37"><pre class="sourceCode stan code-with-copy"><code class="sourceCode stan"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="dt">matrix</span>[size(a), size(b)] a_b;</span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span>:size(a)) {</span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (j <span class="cf">in</span> <span class="dv">1</span>:size(b)) {</span>
<span id="cb37-4"><a href="#cb37-4" aria-hidden="true" tabindex="-1"></a>    a_b[i, j] = a[i] + b[j];</span>
<span id="cb37-5"><a href="#cb37-5" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb37-6"><a href="#cb37-6" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Then the sum can be replaced with <code>a_b[ii[n], jj[n]]</code>.</p>
</section>
<section id="exploiting-conjugacy" class="level2">
<h2 class="anchored" data-anchor-id="exploiting-conjugacy">Exploiting conjugacy</h2>
<p>Continuing the model from the previous section, the conjugacy of the beta prior and binomial distribution allow the model to be further optimized to the following equivalent form.</p>
<div class="sourceCode" id="cb38"><pre class="sourceCode stan code-with-copy"><code class="sourceCode stan"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a>theta ~ beta(alpha + sum(y), beta + N - sum(y));</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>To make the model even more efficient, a transformed data variable defined to be <code>sum(y)</code> could be used in the place of <code>sum(y)</code>.</p>
</section>
<section id="standardizing-predictors" class="level2">
<h2 class="anchored" data-anchor-id="standardizing-predictors">Standardizing predictors</h2>
<p>Standardizing the data so that all predictors have a zero sample mean and unit sample variance has the following potential benefits:</p>
<ul>
<li>It helps in faster convergence of MCMC chains.</li>
<li>It makes the model less sensitive to the specifics of the parameterization.</li>
<li>It aids in the interpretation and comparison of the importance of coefficients across different predictors.</li>
</ul>
<p>When there are large differences between the units and scales of the predictors, standardizing the predictors is especially useful. This section illustrates the principle for a simple linear regression.</p>
<p>Suppose that <span class="math inline">\(y = (y_1,\dotsc,y_N)\)</span> is a vector of <span class="math inline">\(N\)</span> outcomes and <span class="math inline">\(x = (x_1,\dotsc,x_N)\)</span> the corresponding vector of <span class="math inline">\(N\)</span> predictors. A simple linear regression involving an intercept coefficient <span class="math inline">\(\alpha\)</span> and slope coefficient <span class="math inline">\(\beta\)</span> can be expressed as <span class="math display">\[
y_n = \alpha + \beta x_n + \epsilon_n,
\]</span> where <span class="math display">\[
\epsilon_n \sim \textsf{normal}(0,\sigma).
\]</span></p>
<p>If <span class="math inline">\(x\)</span> has very large or very small values or if the mean of the values is far away from 0 (on the scale of the values), then it can be more efficient to standardize the predictor values <span class="math inline">\(x_n\)</span>. First the elements of <span class="math inline">\(x\)</span> are zero-centered by subtracting the mean, then scaled by dividing by the standard deviation.</p>
<p>The mean of <span class="math inline">\(x\)</span> is given by:</p>
<p><span class="math display">\[
mean_x = \frac{1}{N} \sum_{n=1}^{N} x_n
\]</span></p>
<p>The standard deviation of <span class="math inline">\(x\)</span> is calculated as: <span class="math display">\[
sd_x = {\left({\frac{1}{N} \sum_{n=1}^{N} (x_n - mean_x)^2}\right)}^{1/2}
\]</span></p>
<p>With these, we compute the <span class="math inline">\(z\)</span>, the standardized predictors</p>
<p><span class="math display">\[
z_n = \frac{x_n - mean_x}{sd_x}
\]</span></p>
<p>where <span class="math inline">\(z_n\)</span> is the standardized value corresponding to <span class="math inline">\(x_n\)</span>.</p>
<p>The inverse transform is defined by reversing the two normalization steps, first rescaling by the same deviation and relocating by the sample mean.</p>
<p><span class="math display">\[
x_n = z_n sd_x + mean_x
\]</span></p>
<p>Standardizing the predictors standardizes the scale of the variables, and hence the scale of the priors.</p>
<p>Consider the following initial model.</p>
<div class="sourceCode" id="cb39"><pre class="sourceCode stan code-with-copy"><code class="sourceCode stan"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="kw">data</span> {</span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a>  <span class="dt">int</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>&gt; N;</span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a>  <span class="dt">vector</span>[N] y;</span>
<span id="cb39-4"><a href="#cb39-4" aria-hidden="true" tabindex="-1"></a>  <span class="dt">vector</span>[N] x;</span>
<span id="cb39-5"><a href="#cb39-5" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb39-6"><a href="#cb39-6" aria-hidden="true" tabindex="-1"></a><span class="kw">parameters</span> {</span>
<span id="cb39-7"><a href="#cb39-7" aria-hidden="true" tabindex="-1"></a>  <span class="dt">real</span> alpha;</span>
<span id="cb39-8"><a href="#cb39-8" aria-hidden="true" tabindex="-1"></a>  <span class="dt">real</span> beta;</span>
<span id="cb39-9"><a href="#cb39-9" aria-hidden="true" tabindex="-1"></a>  <span class="dt">real</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>&gt; sigma;</span>
<span id="cb39-10"><a href="#cb39-10" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb39-11"><a href="#cb39-11" aria-hidden="true" tabindex="-1"></a><span class="kw">model</span> {</span>
<span id="cb39-12"><a href="#cb39-12" aria-hidden="true" tabindex="-1"></a>  <span class="co">// priors</span></span>
<span id="cb39-13"><a href="#cb39-13" aria-hidden="true" tabindex="-1"></a>  alpha ~ normal(<span class="dv">0</span>, <span class="dv">10</span>);</span>
<span id="cb39-14"><a href="#cb39-14" aria-hidden="true" tabindex="-1"></a>  beta ~ normal(<span class="dv">0</span>, <span class="dv">10</span>);</span>
<span id="cb39-15"><a href="#cb39-15" aria-hidden="true" tabindex="-1"></a>  sigma ~ normal(<span class="dv">0</span>, <span class="dv">5</span>);</span>
<span id="cb39-16"><a href="#cb39-16" aria-hidden="true" tabindex="-1"></a>  <span class="co">// likelihood</span></span>
<span id="cb39-17"><a href="#cb39-17" aria-hidden="true" tabindex="-1"></a>  y ~ normal(x * beta + alpha, sigma);</span>
<span id="cb39-18"><a href="#cb39-18" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>The data block for the standardized model is identical. The mean and standard deviation of the data are defined in the transformed data block, along with the standardized predictors.</p>
<div class="sourceCode" id="cb40"><pre class="sourceCode stan code-with-copy"><code class="sourceCode stan"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a><span class="kw">data</span> {</span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a>  <span class="dt">int</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>&gt; N;</span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a>  <span class="dt">vector</span>[N] y;</span>
<span id="cb40-4"><a href="#cb40-4" aria-hidden="true" tabindex="-1"></a>  <span class="dt">vector</span>[N] x;</span>
<span id="cb40-5"><a href="#cb40-5" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb40-6"><a href="#cb40-6" aria-hidden="true" tabindex="-1"></a><span class="kw">transformed data</span> {</span>
<span id="cb40-7"><a href="#cb40-7" aria-hidden="true" tabindex="-1"></a>  <span class="dt">real</span> mean_x = mean(x);</span>
<span id="cb40-8"><a href="#cb40-8" aria-hidden="true" tabindex="-1"></a>  <span class="dt">real</span> sd_x = sd(x);</span>
<span id="cb40-9"><a href="#cb40-9" aria-hidden="true" tabindex="-1"></a>  <span class="dt">vector</span>[N] x_std = (x - mean_x) / sd_x;</span>
<span id="cb40-10"><a href="#cb40-10" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb40-11"><a href="#cb40-11" aria-hidden="true" tabindex="-1"></a><span class="kw">parameters</span> {</span>
<span id="cb40-12"><a href="#cb40-12" aria-hidden="true" tabindex="-1"></a>  <span class="dt">real</span> alpha_std;</span>
<span id="cb40-13"><a href="#cb40-13" aria-hidden="true" tabindex="-1"></a>  <span class="dt">real</span> beta_std;</span>
<span id="cb40-14"><a href="#cb40-14" aria-hidden="true" tabindex="-1"></a>  <span class="dt">real</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>&gt; sigma_std;</span>
<span id="cb40-15"><a href="#cb40-15" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb40-16"><a href="#cb40-16" aria-hidden="true" tabindex="-1"></a><span class="kw">model</span> {</span>
<span id="cb40-17"><a href="#cb40-17" aria-hidden="true" tabindex="-1"></a>  alpha_std ~ normal(<span class="dv">0</span>, <span class="dv">10</span>);</span>
<span id="cb40-18"><a href="#cb40-18" aria-hidden="true" tabindex="-1"></a>  beta_std ~ normal(<span class="dv">0</span>, <span class="dv">10</span>);</span>
<span id="cb40-19"><a href="#cb40-19" aria-hidden="true" tabindex="-1"></a>  sigma_std ~ normal(<span class="dv">0</span>, <span class="dv">5</span>);</span>
<span id="cb40-20"><a href="#cb40-20" aria-hidden="true" tabindex="-1"></a>  y ~ normal(x_std * beta_std + alpha_std, sigma_std);</span>
<span id="cb40-21"><a href="#cb40-21" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>The parameters are renamed to indicate that they aren’t the “natural” parameters. The transformed data <code>x_std</code> is defined in terms of variables <code>mean_x</code> and <code>sd_x</code>; by declaring these variables in the <code>transformed data</code> block, they will be available in all following blocks, and therefore can be used in the <code>generated quantities</code> block to record the “natural” parameters <code>alpha</code> and <code>beta</code>.</p>
<p>The fairly diffuse priors on the coefficients are the same. These could have been transformed as well, but here they are left as is, because the scales make sense as diffuse priors for standardized data.</p>
<p>The original regression <span class="math display">\[
y_n = \alpha + \beta x_n + \epsilon_n
\]</span> has been transformed to a regression on the standardized data variable <span class="math inline">\(z\)</span>,</p>
<p><span class="math display">\[
y_n = \alpha' + \beta' z_n + \epsilon_n.
\]</span></p>
<p>The likelihood is specified in terms of the standardized parameters. The original slope <span class="math inline">\(\beta\)</span> is the standardized slope <span class="math inline">\(\beta'\)</span> scaled by the inverse of the standard deviation of <span class="math inline">\(x\)</span>. The original intercept <span class="math inline">\(\alpha\)</span> is the intercept from the standardized model <span class="math inline">\(\alpha'\)</span>, corrected for the effect of scaling and centering <span class="math inline">\(x\)</span>. Thus, the formulas to retrieve <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span> from <span class="math inline">\(\alpha'\)</span> and <span class="math inline">\(\beta'\)</span> are:</p>
<p><span class="math display">\[\begin{align*}
\beta = \frac{\beta'}{\sigma_x} \\
\alpha = \alpha' - \beta' \frac{\mu_x}{\sigma_x}
\end{align*}\]</span></p>
<p>These recovered parameter values on the original scales can be calculated within Stan using a generated quantities block following the model block,</p>
<div class="sourceCode" id="cb41"><pre class="sourceCode stan code-with-copy"><code class="sourceCode stan"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="kw">generated quantities</span> {</span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a>  <span class="dt">real</span> beta = beta_std / sd_x;</span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a>  <span class="dt">real</span> alpha = alpha_std - beta_std * mean_x / sd_x;</span>
<span id="cb41-4"><a href="#cb41-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-5"><a href="#cb41-5" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>When there are multiple real-valued predictors, i.e., when <code>K</code> is the number of predictors, <code>x</code> is an <span class="math inline">\(N \times K\)</span> matrix, and <code>beta</code> ia <span class="math inline">\(K\)</span>-vector of coefficients, then <code>x * beta</code> is an <span class="math inline">\(N\)</span>-vector of predictions, one for each of the <span class="math inline">\(N\)</span> data items. When <span class="math inline">\(K \ll N\)</span> the <a href="../stan-users-guide/regression.html#QR-reparameterization.section">QR reparameterization</a> is recommended for linear and generalized linear models unless there is an informative prior on the location of <span class="math inline">\(\beta\)</span>.</p>
<section id="standard-normal-distribution" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="standard-normal-distribution">Standard normal distribution</h3>
<p>For many applications on the standard scale, normal distributions with location zero and scale one will be used. In these cases, it is more efficient to use</p>
<div class="sourceCode" id="cb42"><pre class="sourceCode stan code-with-copy"><code class="sourceCode stan"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a>y ~ std_normal();</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>than to use</p>
<div class="sourceCode" id="cb43"><pre class="sourceCode stan code-with-copy"><code class="sourceCode stan"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a>y ~ normal(<span class="dv">0</span>, <span class="dv">1</span>);</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>because the subtraction of the location and division by the scale cancel, as does subtracting the log of the scale.</p>
</section>
</section>
<section id="using-map-reduce" class="level2">
<h2 class="anchored" data-anchor-id="using-map-reduce">Using map-reduce</h2>
<p>The map-reduce operation, even without multi-core MPI support, can be used to make programs more scalable and also more efficient. See the <a href="../stan-users-guide/parallelization.html">map-reduce chapter</a> for more information on implementing map-reduce operations.</p>
<p>Map-reduce allows greater scalability because only the Jacobian of the mapped function for each shard is stored. The Jacobian consists of all of the derivatives of the outputs with respect to the parameters. During execution, the derivatives of the shard are evaluated using nested automatic differentiation. As often happens with modern CPUs, reduced memory overhead leads to increased memory locality and faster execution. The Jacobians are all computed with local memory and their outputs stored contiguously in memory.</p>



</section>
</section>


<a onclick="window.scrollTo(0, 0); return false;" role="button" id="quarto-back-to-top"><i class="bi bi-arrow-up"></i> Back to top</a><div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-Betancourt-Girolami:2013" class="csl-entry" role="listitem">
Betancourt, Michael, and Mark Girolami. 2013. <span>“<span>H</span>amiltonian <span>M</span>onte <span>C</span>arlo for Hierarchical Models.”</span> <em>arXiv</em> 1312.0906. <a href="http://arxiv.org/abs/1312.0906">http://arxiv.org/abs/1312.0906</a>.
</div>
<div id="ref-Neal:2003" class="csl-entry" role="listitem">
Neal, Radford M. 2003. <span>“Slice Sampling.”</span> <em>Annals of Statistics</em> 31 (3): 705–67.
</div>
<div id="ref-papa-et-al:2007" class="csl-entry" role="listitem">
Papaspiliopoulos, Omiros, Gareth O. Roberts, and Martin Sköld. 2007. <span>“A General Framework for the Parametrization of Hierarchical Models.”</span> <em>Statistical Science</em> 22 (1): 59–73.
</div>
<div id="ref-ZyczkowskiSommers:2001" class="csl-entry" role="listitem">
Zyczkowski, K., and H. J. Sommers. 2001. <span>“Induced Measures in the Space of Mixed Quantum States.”</span> <em>Journal of Physics A: Mathematical and General</em> 34 (35): 7111.
</div>
</div></section><section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>This parameterization came to be known on our mailing lists as the “Matt trick” after Matt Hoffman, who independently came up with it while fitting hierarchical models in Stan.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>Stan uses its own arena-based allocation, so allocation and deallocation are faster than with a raw call to <code>new</code>.<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>Future versions of Stan may remove this inefficiency by more fully exploiting expression templates inside the Eigen C++ matrix library. This will require enhancing Eigen to deal with mixed-type arguments, such as the type <code>double</code> used for constants and the algorithmic differentiation type <code>stan::math::var</code> used for variables.<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
    const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
    const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
    let newTheme = '';
    if(darkModeDefault) {
      newTheme = isAlternate ? baseTheme : alternateTheme;
    } else {
      newTheme = isAlternate ? alternateTheme : baseTheme;
    }
    const changeGiscusTheme = () => {
      // From: https://github.com/giscus/giscus/issues/336
      const sendMessage = (message) => {
        const iframe = document.querySelector('iframe.giscus-frame');
        if (!iframe) return;
        iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
      }
      sendMessage({
        setConfig: {
          theme: newTheme
        }
      });
    }
    const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
    if (isGiscussLoaded) {
      changeGiscusTheme();
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  const darkModeDefault = false;
  let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
    toggleGiscusIfUsed(toAlternate, darkModeDefault);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../stan-users-guide/reparameterization.html" class="pagination-link" aria-label="Reparameterization and Change of Variables">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text">Reparameterization and Change of Variables</span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../stan-users-guide/parallelization.html" class="pagination-link" aria-label="Parallelization">
        <span class="nav-page-text">Parallelization</span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




<footer class="footer"><div class="nav-footer"><div class="nav-footer-center"><div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/stan-dev/docs/edit/master/src/stan-users-guide/efficiency-tuning.qmd" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li><li><a href="https://github.com/stan-dev/docs/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div></div></div></footer></body></html>